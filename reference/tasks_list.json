{
  "tasks": {
    "assin2_rte": {
      "name": "assin2_rte",
      "group": "latam_pr",
      "description": "Portuguese RTE (Recognizing Textual Entailment) from ASSIN2",
      "description_en": "Portuguese RTE (Recognizing Textual Entailment) from ASSIN2",
      "description_es": "RTE en portugu\u00e9s (reconocimiento de inferencia textual) de ASSIN2",
      "description_pt": "RTE em portugu\u00eas (Reconhecimento de Entailment Textual) do ASSIN2",
      "long_description": "ASSIN2 (Avalia\u00e7\u00e3o de Similaridade Sem\u00e2ntica e de Infer\u00eancia Textual) is a Brazilian Portuguese benchmark. This RTE configuration predicts whether a hypothesis is entailed by a premise for sentence pairs in PT-BR, enabling evaluation of textual inference capabilities.",
      "long_description_en": "ASSIN2 (Semantic Similarity and Textual Inference Evaluation) is a Brazilian Portuguese benchmark. This RTE setup predicts whether a hypothesis is entailed by a premise for PT-BR sentence pairs, enabling evaluation of textual inference.",
      "long_description_es": "ASSIN2 (Evaluaci\u00f3n de Similitud Sem\u00e1ntica e Inferencia Textual) es un benchmark en portugu\u00e9s de Brasil. Esta configuraci\u00f3n de RTE predice si una hip\u00f3tesis se infiere de una premisa para pares de oraciones en PT-BR, evaluando la inferencia textual.",
      "long_description_pt": "ASSIN2 (Avalia\u00e7\u00e3o de Similaridade Sem\u00e2ntica e de Infer\u00eancia Textual) \u00e9 um benchmark em portugu\u00eas do Brasil. Esta configura\u00e7\u00e3o de RTE prev\u00ea se uma hip\u00f3tese \u00e9 implicada por uma premissa em pares de frases em PT-BR, avaliando a infer\u00eancia textual.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/nilc-nlp/assin2"
    },
    "assin2_sts": {
      "name": "assin2_sts",
      "group": "latam_pr",
      "description": "Portuguese STS (Semantic Textual Similarity) from ASSIN2",
      "description_en": "Portuguese STS (Semantic Textual Similarity) from ASSIN2",
      "description_es": "STS en portugu\u00e9s (similitud sem\u00e1ntica textual) de ASSIN2",
      "description_pt": "STS em portugu\u00eas (Similaridade Textual Sem\u00e2ntica) do ASSIN2",
      "long_description": "The ASSIN2 STS track measures semantic similarity between pairs of Brazilian Portuguese sentences on a 1\u20135 scale. It evaluates fine-grained understanding of meaning and paraphrase in PT-BR.",
      "long_description_en": "The ASSIN2 STS track measures semantic similarity between pairs of Brazilian Portuguese sentences on a 1\u20135 scale, evaluating nuanced understanding of meaning and paraphrase in PT-BR.",
      "long_description_es": "La pista STS de ASSIN2 mide la similitud sem\u00e1ntica entre pares de oraciones en portugu\u00e9s de Brasil en una escala de 1\u20135, evaluando la comprensi\u00f3n fina del significado y la par\u00e1frasis en PT-BR.",
      "long_description_pt": "A trilha STS do ASSIN2 mede a similaridade sem\u00e2ntica entre pares de frases em portugu\u00eas do Brasil em uma escala de 1\u20135, avaliando a compreens\u00e3o detalhada de significado e par\u00e1frase em PT-BR.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/nilc-nlp/assin2"
    },
    "bluex": {
      "name": "bluex",
      "group": "latam_pr",
      "description": "Portuguese BLUEX benchmark",
      "description_en": "Portuguese BLUEX benchmark",
      "description_es": "Benchmark portugu\u00e9s BLUEX",
      "description_pt": "Benchmark portugu\u00eas BLUEX",
      "long_description": "BLUEX is a multiple-choice benchmark built from Brazilian university entrance exams (vestibulares), covering diverse subjects in Portuguese. This configuration uses a version without images to allow pure text evaluation.",
      "long_description_en": "BLUEX is a multiple-choice benchmark built from Brazilian university entrance exams (vestibulares), covering diverse subjects in Portuguese. This setup uses a version without images to allow text-only evaluation.",
      "long_description_es": "BLUEX es un benchmark de opci\u00f3n m\u00faltiple construido a partir de ex\u00e1menes de ingreso universitario brasile\u00f1os (vestibulares), que cubre diversas materias en portugu\u00e9s. Esta configuraci\u00f3n sin im\u00e1genes permite evaluaci\u00f3n solo con texto.",
      "long_description_pt": "BLUEX \u00e9 um benchmark de m\u00faltipla escolha constru\u00eddo a partir de vestibulares brasileiros, cobrindo diversas disciplinas em portugu\u00eas. Esta configura\u00e7\u00e3o sem imagens permite avalia\u00e7\u00e3o apenas em texto.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/eduagarcia-temp/BLUEX_without_images"
    },
    "enem_challenge": {
      "name": "enem_challenge",
      "group": "latam_pr",
      "description": "Multiple Choice Questions from the ENEM Exam",
      "description_en": "Multiple-choice questions from the ENEM exam",
      "description_es": "Preguntas de opci\u00f3n m\u00faltiple del examen ENEM",
      "description_pt": "Quest\u00f5es de m\u00faltipla escolha do exame ENEM",
      "long_description": "University Entrance Exam as a Guiding Test for Artificial Intelligence\nhttps://www.ime.usp.br/~ddm/project/enem/ENEM-GuidingTest.pdf\n\nThe ENEM Challenge consists in designing an autonomous system that matches the performance of a human students on the exam. The overall goal is to foster and evaluate the development of Artificial Intelligence techniques that have good performance on complex cognitive tasks, not particularly designed for AI systems. In addition, this challenge aims to promote and give more visiblity to the development of NLP tools for Brazilian Portuguese.\n\nHomepage: https://www.ime.usp.br/~ddm/project/enem",
      "long_description_en": "University Entrance Exam as a Guiding Test for Artificial Intelligence\nhttps://www.ime.usp.br/~ddm/project/enem/ENEM-GuidingTest.pdf\n\nThe ENEM Challenge consists of designing an autonomous system that matches the performance of human students on the exam. The goal is to foster and evaluate AI techniques that perform well on complex cognitive tasks not specifically designed for AI, while promoting the development of NLP tools for Brazilian Portuguese.\n\nHomepage: https://www.ime.usp.br/~ddm/project/enem",
      "long_description_es": "Examen de ingreso universitario como prueba gu\u00eda para la inteligencia artificial\nhttps://www.ime.usp.br/~ddm/project/enem/ENEM-GuidingTest.pdf\n\nEl Desaf\u00edo ENEM consiste en dise\u00f1ar un sistema aut\u00f3nomo que iguale el desempe\u00f1o de estudiantes humanos en el examen. El objetivo es fomentar y evaluar t\u00e9cnicas de IA que funcionen bien en tareas cognitivas complejas no dise\u00f1adas espec\u00edficamente para IA, adem\u00e1s de promover el desarrollo de herramientas de PLN para el portugu\u00e9s brasile\u00f1o.\n\nP\u00e1gina: https://www.ime.usp.br/~ddm/project/enem",
      "long_description_pt": "Exame de ingresso universit\u00e1rio como teste orientador para intelig\u00eancia artificial\nhttps://www.ime.usp.br/~ddm/project/enem/ENEM-GuidingTest.pdf\n\nO Desafio ENEM consiste em projetar um sistema aut\u00f4nomo que atinja o desempenho de estudantes humanos no exame. O objetivo \u00e9 fomentar e avaliar t\u00e9cnicas de IA com bom desempenho em tarefas cognitivas complexas n\u00e3o projetadas especificamente para IA, al\u00e9m de promover o desenvolvimento de ferramentas de PLN para o portugu\u00eas do Brasil.\n\nP\u00e1gina: https://www.ime.usp.br/~ddm/project/enem",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/eduagarcia/enem_challenge"
    },
    "oab_exams": {
      "name": "oab_exams",
      "group": "latam_pr",
      "description": "Portuguese OAB (Brazilian Bar Association) exams",
      "description_en": "Portuguese OAB (Brazilian Bar Association) exams",
      "description_es": "Ex\u00e1menes de la OAB (abogac\u00eda brasile\u00f1a) en portugu\u00e9s",
      "description_pt": "Exames da OAB (Ordem dos Advogados do Brasil) em portugu\u00eas",
      "long_description": "Multiple-choice questions from Brazil's OAB Bar examinations across legal domains. Evaluates legal reasoning, reading comprehension, and knowledge of Brazilian law in Portuguese.",
      "long_description_en": "Multiple-choice questions from Brazil's OAB Bar exams across legal domains. Evaluates legal reasoning, reading comprehension, and knowledge of Brazilian law in Portuguese.",
      "long_description_es": "Preguntas de opci\u00f3n m\u00faltiple de los ex\u00e1menes de la OAB de Brasil en distintos \u00e1mbitos jur\u00eddicos. Eval\u00faa razonamiento legal, comprensi\u00f3n lectora y conocimiento del derecho brasile\u00f1o en portugu\u00e9s.",
      "long_description_pt": "Quest\u00f5es de m\u00faltipla escolha dos exames da OAB do Brasil em v\u00e1rias \u00e1reas do direito. Avalia racioc\u00ednio jur\u00eddico, compreens\u00e3o de leitura e conhecimento do direito brasileiro em portugu\u00eas.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/eduagarcia/oab_exams"
    },
    "copa_es": {
      "name": "copa_es",
      "group": "latam_es",
      "description": "Spanish COPA (Choice of Plausible Alternatives)",
      "description_en": "Spanish COPA (Choice of Plausible Alternatives)",
      "description_es": "COPA en espa\u00f1ol (elecci\u00f3n de alternativas plausibles)",
      "description_pt": "COPA em espanhol (escolha de alternativas plaus\u00edveis)",
      "long_description": "Spanish version of COPA, a commonsense causal reasoning benchmark. Given a premise and a relation (cause/effect), the model selects the more plausible alternative in Spanish.",
      "long_description_en": "Spanish version of COPA, a commonsense causal reasoning benchmark. Given a premise and a relation (cause/effect), the model selects the more plausible alternative in Spanish.",
      "long_description_es": "Versi\u00f3n en espa\u00f1ol de COPA, un benchmark de razonamiento causal de sentido com\u00fan. Dada una premisa y una relaci\u00f3n (causa/efecto), el modelo elige la alternativa m\u00e1s plausible en espa\u00f1ol.",
      "long_description_pt": "Vers\u00e3o em espanhol do COPA, benchmark de racioc\u00ednio causal de senso comum. Dada uma premissa e uma rela\u00e7\u00e3o (causa/efeito), o modelo escolhe a alternativa mais plaus\u00edvel em espanhol.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/BSC-LT/COPA-es"
    },
    "escola": {
      "name": "escola",
      "group": "latam_es",
      "description": "Spanish EsCoLA (Spanish Corpus of Linguistic Acceptability)",
      "description_en": "Spanish EsCoLA (Spanish Corpus of Linguistic Acceptability)",
      "description_es": "EsCoLA en espa\u00f1ol (Corpus de Aceptabilidad Ling\u00fc\u00edstica en Espa\u00f1ol)",
      "description_pt": "EsCoLA em espanhol (Corpus de Aceitabilidade Lingu\u00edstica em Espanhol)",
      "long_description": "EsCoLA contains Spanish sentences annotated for linguistic acceptability. The task is a binary judgment (acceptable vs. unacceptable), probing grammatical knowledge and fluency in Spanish.",
      "long_description_en": "EsCoLA contains Spanish sentences annotated for linguistic acceptability. The task is a binary judgment (acceptable vs. unacceptable), probing grammatical knowledge and fluency in Spanish.",
      "long_description_es": "EsCoLA contiene oraciones en espa\u00f1ol anotadas por aceptabilidad ling\u00fc\u00edstica. Es un juicio binario (aceptable vs. inaceptable) que explora conocimiento gramatical y fluidez.",
      "long_description_pt": "EsCoLA cont\u00e9m frases em espanhol anotadas quanto \u00e0 aceitabilidade lingu\u00edstica. A tarefa \u00e9 um julgamento bin\u00e1rio (aceit\u00e1vel vs. inaceit\u00e1vel) que explora conhecimento gramatical e flu\u00eancia.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/nbel/EsCoLA"
    },
    "mgsm_direct_es_spanish_bench": {
      "name": "mgsm_direct_es_spanish_bench",
      "group": "latam_es",
      "description": "Spanish MGSM (Multilingual Grade School Math)",
      "description_en": "Spanish MGSM (Multilingual Grade School Math)",
      "description_es": "MGSM en espa\u00f1ol (matem\u00e1tica escolar multiling\u00fce)",
      "description_pt": "MGSM em espanhol (matem\u00e1tica escolar multil\u00edngue)",
      "long_description": "Spanish subset of MGSM, a multilingual grade-school math benchmark. This configuration expects direct numeric answers (no chain-of-thought), evaluating arithmetic and reasoning in Spanish.",
      "long_description_en": "Spanish subset of MGSM, a multilingual grade-school math benchmark. This configuration expects direct numeric answers (no chain-of-thought), evaluating arithmetic and reasoning in Spanish.",
      "long_description_es": "Subconjunto en espa\u00f1ol de MGSM, benchmark multiling\u00fce de matem\u00e1tica escolar. Esta configuraci\u00f3n espera respuestas num\u00e9ricas directas (sin cadena de razonamiento), evaluando aritm\u00e9tica y razonamiento en espa\u00f1ol.",
      "long_description_pt": "Subconjunto em espanhol do MGSM, benchmark multil\u00edngue de matem\u00e1tica escolar. Esta configura\u00e7\u00e3o espera respostas num\u00e9ricas diretas (sem cadeia de racioc\u00ednio), avaliando aritm\u00e9tica e racioc\u00ednio em espanhol.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/juletxara/mgsm"
    },
    "openbookqa_es": {
      "name": "openbookqa_es",
      "group": "latam_es",
      "description": "Spanish OpenBookQA",
      "description_en": "Spanish OpenBookQA",
      "description_es": "OpenBookQA en espa\u00f1ol",
      "description_pt": "OpenBookQA em espanhol",
      "long_description": "Spanish adaptation of OpenBookQA, a multiple-choice science QA benchmark requiring use of elementary science facts plus commonsense reasoning, localized to Spanish.",
      "long_description_en": "Spanish adaptation of OpenBookQA, a multiple-choice science QA benchmark requiring use of elementary science facts plus commonsense reasoning, localized to Spanish.",
      "long_description_es": "Adaptaci\u00f3n al espa\u00f1ol de OpenBookQA, benchmark de preguntas de ciencia de opci\u00f3n m\u00faltiple que requiere usar hechos cient\u00edficos elementales y razonamiento de sentido com\u00fan.",
      "long_description_pt": "Adapta\u00e7\u00e3o em espanhol do OpenBookQA, benchmark de perguntas de ci\u00eancia de m\u00faltipla escolha que exige fatos cient\u00edficos b\u00e1sicos e racioc\u00ednio de senso comum.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/BSC-LT/openbookqa-es"
    },
    "paws_es_spanish_bench": {
      "name": "paws_es_spanish_bench",
      "group": "latam_es",
      "description": "Spanish PAWS (Paraphrase Adversaries from Word Scrambling)",
      "description_en": "Spanish PAWS (Paraphrase Adversaries from Word Scrambling)",
      "description_es": "PAWS en espa\u00f1ol (par\u00e1frasis con alta superposici\u00f3n l\u00e9xica)",
      "description_pt": "PAWS em espanhol (par\u00e1frases com alta sobreposi\u00e7\u00e3o lexical)",
      "long_description": "PAWS-X Spanish evaluates paraphrase identification with high-lexical-overlap sentence pairs. The model must determine whether two Spanish sentences are paraphrases.",
      "long_description_en": "PAWS-X Spanish evaluates paraphrase identification with sentence pairs that have high lexical overlap. The model must decide whether two Spanish sentences are paraphrases.",
      "long_description_es": "PAWS-X en espa\u00f1ol eval\u00faa la identificaci\u00f3n de par\u00e1frasis con pares de oraciones de alta superposici\u00f3n l\u00e9xica. El modelo debe decidir si dos oraciones en espa\u00f1ol son par\u00e1frasis.",
      "long_description_pt": "PAWS-X em espanhol avalia a identifica\u00e7\u00e3o de par\u00e1frases com pares de senten\u00e7as de alta sobreposi\u00e7\u00e3o lexical. O modelo deve decidir se duas senten\u00e7as em espanhol s\u00e3o par\u00e1frases.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/google-research-datasets/paws-x"
    },
    "teleia_pce": {
      "name": "teleia_pce",
      "group": "latam_es",
      "description": "Teleia PCE (Prueba de Conocimientos Espec\u00edficos)",
      "description_en": "Teleia PCE (Specific Knowledge Test)",
      "description_es": "Teleia PCE (Prueba de Conocimientos Espec\u00edficos)",
      "description_pt": "Teleia PCE (Prova de Conhecimentos Espec\u00edficos)",
      "long_description": "Teleia Spanish assessment suite \u2013 PCE (specific knowledge) subtask. Three-option multiple-choice questions that evaluate formal Spanish knowledge and usage.",
      "long_description_en": "Teleia Spanish assessment suite \u2013 PCE (specific knowledge) subtask. Three-option multiple-choice questions that evaluate formal Spanish knowledge and usage.",
      "long_description_es": "Suite de evaluaci\u00f3n de espa\u00f1ol Teleia \u2013 subtarea PCE (conocimientos espec\u00edficos). Preguntas de opci\u00f3n m\u00faltiple de tres opciones que eval\u00faan conocimiento y uso formal del espa\u00f1ol.",
      "long_description_pt": "Su\u00edte de avalia\u00e7\u00e3o de espanhol Teleia \u2013 subtarefa PCE (conhecimentos espec\u00edficos). Quest\u00f5es de m\u00faltipla escolha com tr\u00eas op\u00e7\u00f5es que avaliam conhecimento e uso formal do espanhol.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/migonsa/teleia"
    },
    "teleia_cervantes_ave": {
      "name": "teleia_cervantes_ave",
      "group": "latam_es",
      "description": "Teleia Cervantes AVE assessment",
      "description_en": "Teleia Cervantes AVE assessment",
      "description_es": "Evaluaci\u00f3n Teleia Cervantes AVE",
      "description_pt": "Avalia\u00e7\u00e3o Teleia Cervantes AVE",
      "long_description": "Teleia Spanish assessment suite \u2013 Cervantes AVE subtask. Multiple-choice questions targeting Spanish language competency (reading and grammar) with dataset_name=cervantes_ave.",
      "long_description_en": "Teleia Spanish assessment suite \u2013 Cervantes AVE subtask. Multiple-choice questions targeting Spanish language competency (reading and grammar) with dataset_name=cervantes_ave.",
      "long_description_es": "Suite de evaluaci\u00f3n de espa\u00f1ol Teleia \u2013 subtarea Cervantes AVE. Preguntas de opci\u00f3n m\u00faltiple enfocadas en competencia en espa\u00f1ol (comprensi\u00f3n y gram\u00e1tica), con dataset_name=cervantes_ave.",
      "long_description_pt": "Su\u00edte de avalia\u00e7\u00e3o de espanhol Teleia \u2013 subtarefa Cervantes AVE. Quest\u00f5es de m\u00faltipla escolha focadas em compet\u00eancia em espanhol (leitura e gram\u00e1tica), com dataset_name=cervantes_ave.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/migonsa/teleia"
    },
    "teleia_siele": {
      "name": "teleia_siele",
      "group": "latam_es",
      "description": "Teleia SIELE (Servicio Internacional de Evaluaci\u00f3n de la Lengua Espa\u00f1ola)",
      "description_en": "Teleia SIELE (International Spanish Language Evaluation Service)",
      "description_es": "Teleia SIELE (Servicio Internacional de Evaluaci\u00f3n de la Lengua Espa\u00f1ola)",
      "description_pt": "Teleia SIELE (Servi\u00e7o Internacional de Avalia\u00e7\u00e3o da L\u00edngua Espanhola)",
      "long_description": "Teleia Spanish assessment suite \u2013 SIELE-inspired subtask. Three-option multiple-choice items covering comprehension and grammatical accuracy in Spanish.",
      "long_description_en": "Teleia Spanish assessment suite \u2013 SIELE-inspired subtask. Three-option multiple-choice items covering comprehension and grammatical accuracy in Spanish.",
      "long_description_es": "Suite de evaluaci\u00f3n de espa\u00f1ol Teleia \u2013 subtarea inspirada en SIELE. \u00cdtems de opci\u00f3n m\u00faltiple con tres opciones que cubren comprensi\u00f3n y correcci\u00f3n gramatical en espa\u00f1ol.",
      "long_description_pt": "Su\u00edte de avalia\u00e7\u00e3o de espanhol Teleia \u2013 subtarefa inspirada no SIELE. Itens de m\u00faltipla escolha com tr\u00eas op\u00e7\u00f5es cobrindo compreens\u00e3o e corre\u00e7\u00e3o gramatical em espanhol.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/migonsa/teleia"
    },
    "wnli_es": {
      "name": "wnli_es",
      "group": "latam_es",
      "description": "Spanish WNLI (Winograd Natural Language Inference)",
      "description_en": "Spanish WNLI (Winograd Natural Language Inference)",
      "description_es": "WNLI en espa\u00f1ol (inferencia Winograd)",
      "description_pt": "WNLI em espanhol (infer\u00eancia Winograd)",
      "long_description": "Spanish WNLI is a localized Winograd-style NLI task. Given two sentences, the model decides whether the second follows (Verdadero) from the first or not (Falso).",
      "long_description_en": "Spanish WNLI is a localized Winograd-style NLI task. Given two sentences, the model decides whether the second follows (Verdadero) from the first or not (Falso).",
      "long_description_es": "WNLI en espa\u00f1ol es una tarea de NLI de estilo Winograd localizada. Dadas dos oraciones, el modelo decide si la segunda se sigue (Verdadero) de la primera o no (Falso).",
      "long_description_pt": "WNLI em espanhol \u00e9 uma tarefa de NLI no estilo Winograd. Dadas duas senten\u00e7as, o modelo decide se a segunda decorre (Verdadeiro) da primeira ou n\u00e3o (Falso).",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/PlanTL-GOB-ES/wnli-es"
    },
    "opus": {
      "name": "opus",
      "group": "translation",
      "description": "OPUS-100 English-centric translation evaluation",
      "description_en": "OPUS-100 English-centric translation evaluation",
      "description_es": "Evaluaci\u00f3n de traducci\u00f3n OPUS-100 centrada en ingl\u00e9s",
      "description_pt": "Avalia\u00e7\u00e3o de tradu\u00e7\u00e3o OPUS-100 centrada em ingl\u00eas",
      "long_description": "OPUS-100 is an English-centric multilingual translation corpus covering 100 languages with approximately 55M sentence pairs. For this evaluation, we focus on English-Spanish and English-Portuguese translation pairs from this large-scale dataset. The corpus was built from the OPUS collection of parallel texts and provides substantial training data with up to 1M sentence pairs per language pair. Translation quality is measured using COMET, BLEU, TER (Translation Error Rate), and chrF metrics, with COMET as the primary reported metric. This benchmark evaluates models' ability to translate between English and major Latin American languages using real-world parallel text data from diverse sources including legal documents, literature, and web content.",
      "long_description_en": "OPUS-100 is an English-centric multilingual translation corpus covering 100 languages with approximately 55M sentence pairs. For this evaluation, we focus on English-Spanish and English-Portuguese translation pairs from this large-scale dataset. The corpus was built from the OPUS collection of parallel texts and provides substantial training data with up to 1M sentence pairs per language pair. Translation quality is measured using COMET, BLEU, TER (Translation Error Rate), and chrF metrics, with COMET as the primary reported metric. This benchmark evaluates models' ability to translate between English and major Latin American languages using real-world parallel text data from diverse sources including legal documents, literature, and web content.",
      "long_description_es": "OPUS-100 es un corpus de traducci\u00f3n multiling\u00fce centrado en ingl\u00e9s que cubre 100 idiomas con aproximadamente 55M pares de oraciones. Para esta evaluaci\u00f3n, nos enfocamos en pares de traducci\u00f3n ingl\u00e9s-espa\u00f1ol e ingl\u00e9s-portugu\u00e9s de este conjunto a gran escala. El corpus se construy\u00f3 a partir de la colecci\u00f3n OPUS de textos paralelos y proporciona datos de entrenamiento sustanciales con hasta 1M de pares de oraciones por par de idiomas. La calidad de traducci\u00f3n se mide usando m\u00e9tricas COMET, BLEU, TER (Tasa de Error de Traducci\u00f3n) y chrF, con COMET como m\u00e9trica principal reportada. Este benchmark eval\u00faa la capacidad de los modelos para traducir entre ingl\u00e9s y principales idiomas latinoamericanos usando datos de texto paralelo del mundo real de fuentes diversas incluyendo documentos legales, literatura y contenido web.",
      "long_description_pt": "OPUS-100 \u00e9 um corpus de tradu\u00e7\u00e3o multil\u00edngue centrado em ingl\u00eas cobrindo 100 idiomas com aproximadamente 55M pares de senten\u00e7as. Para esta avalia\u00e7\u00e3o, focamos em pares de tradu\u00e7\u00e3o ingl\u00eas-espanhol e ingl\u00eas-portugu\u00eas deste conjunto em larga escala. O corpus foi constru\u00eddo a partir da cole\u00e7\u00e3o OPUS de textos paralelos e fornece dados de treinamento substanciais com at\u00e9 1M de pares de senten\u00e7as por par de idiomas. A qualidade da tradu\u00e7\u00e3o \u00e9 medida usando m\u00e9tricas COMET, BLEU, TER (Taxa de Erro de Tradu\u00e7\u00e3o) e chrF, com COMET como m\u00e9trica principal reportada. Este benchmark avalia a capacidade dos modelos de traduzir entre ingl\u00eas e principais idiomas latino-americanos usando dados de texto paralelo do mundo real de fontes diversas incluindo documentos legais, literatura e conte\u00fado web.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/Helsinki-NLP/opus-100"
    },
    "flores": {
      "name": "flores",
      "group": "translation",
      "description": "FLORES+ multilingual translation evaluation",
      "description_en": "FLORES+ multilingual translation evaluation",
      "description_es": "Evaluaci\u00f3n de traducci\u00f3n multiling\u00fce FLORES+",
      "description_pt": "Avalia\u00e7\u00e3o de tradu\u00e7\u00e3o multil\u00edngue FLORES+",
      "long_description": "FLORES+ is a high-quality multilingual translation benchmark covering 30 language pairs focused on Latin American and Iberian languages. The evaluation includes bidirectional translation between Spanish, Portuguese, English, French, Italian, German, Hindi, Chinese and Arabic. Based on the FLORES-200 dataset but with enhanced quality for Latin American language variants, it measures translation accuracy using COMET, BLEU and chrF metrics, with COMET as the primary reported metric. The dataset provides professionally curated parallel sentences across diverse domains to evaluate semantic preservation and linguistic fluency in machine translation systems.",
      "long_description_en": "FLORES+ is a high-quality multilingual translation benchmark covering 30 language pairs focused on Latin American and Iberian languages. The evaluation includes bidirectional translation between Spanish, Portuguese, English, French, Italian, German, Hindi, Chinese and Arabic. Based on the FLORES-200 dataset but with enhanced quality for Latin American language variants, it measures translation accuracy using COMET, BLEU and chrF metrics, with COMET as the primary reported metric. The dataset provides professionally curated parallel sentences across diverse domains to evaluate semantic preservation and linguistic fluency in machine translation systems.",
      "long_description_es": "FLORES+ es un benchmark multiling\u00fce de traducci\u00f3n de alta calidad que cubre 30 pares de idiomas enfocados en lenguas latinoamericanas e ib\u00e9ricas. La evaluaci\u00f3n incluye traducci\u00f3n bidireccional entre espa\u00f1ol, portugu\u00e9s, ingl\u00e9s, franc\u00e9s, italiano, alem\u00e1n, indio, chino y arabe. Basado en el conjunto FLORES-200 pero con calidad mejorada para variantes ling\u00fc\u00edsticas latinoamericanas, mide la precisi\u00f3n de traducci\u00f3n usando m\u00e9tricas COMET, BLEU y chrF, con COMET como m\u00e9trica principal reportada. El conjunto proporciona oraciones paralelas curadas profesionalmente en diversos dominios para evaluar la preservaci\u00f3n sem\u00e1ntica y fluidez ling\u00fc\u00edstica en sistemas de traducci\u00f3n autom\u00e1tica.",
      "long_description_pt": "FLORES+ \u00e9 um benchmark multil\u00edngue de tradu\u00e7\u00e3o de alta qualidade cobrindo 30 pares de idiomas focados em l\u00ednguas latino-americanas e ib\u00e9ricas. A avalia\u00e7\u00e3o inclui tradu\u00e7\u00e3o bidirecional entre espanhol, portugu\u00eas, ingl\u00eas, franc\u00eas, italiano, alem\u00e3o, indiano, chin\u00eas e \u00e1rabe. Baseado no conjunto FLORES-200 mas com qualidade aprimorada para variantes lingu\u00edsticas latino-americanas, mede a precis\u00e3o da tradu\u00e7\u00e3o usando m\u00e9tricas COMET, BLEU e chrF, com COMET como m\u00e9trica principal reportada. O conjunto fornece senten\u00e7as paralelas curadas profissionalmente em diversos dom\u00ednios para avaliar a preserva\u00e7\u00e3o sem\u00e2ntica e flu\u00eancia lingu\u00edstica em sistemas de tradu\u00e7\u00e3o autom\u00e1tica.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/openlanguagedata/flores_plus"
    },
    "paraloq": {
      "name": "paraloq",
      "group": "structured_extraction",
      "description": "Structured JSON data extraction from diverse text sources",
      "description_en": "Structured JSON data extraction from diverse text sources",
      "description_es": "Extracci\u00f3n estructurada de datos JSON de fuentes de texto diversas",
      "description_pt": "Extra\u00e7\u00e3o estruturada de dados JSON de fontes de texto diversas",
      "long_description": "Paraloq evaluates AI systems' capabilities for extracting structured information from unstructured text and returning it in JSON format. Based on the paraloq/json_data_extraction dataset, this task tests models' ability to parse diverse document types including medical records, e-commerce listings, business documents, travel itineraries, media content, technology specifications, and manufacturing reports. The evaluation focuses on the model's precision in extracting all available information while adhering to provided JSON schemas, testing both comprehension and structured output generation capabilities across multiple domains.",
      "long_description_en": "Paraloq evaluates AI systems' capabilities for extracting structured information from unstructured text and returning it in JSON format. Based on the paraloq/json_data_extraction dataset, this task tests models' ability to parse diverse document types including medical records, e-commerce listings, business documents, travel itineraries, media content, technology specifications, and manufacturing reports. The evaluation focuses on the model's precision in extracting all available information while adhering to provided JSON schemas, testing both comprehension and structured output generation capabilities across multiple domains.",
      "long_description_es": "Paraloq eval\u00faa las capacidades de los sistemas de IA para extraer informaci\u00f3n estructurada de texto no estructurado y devolverla en formato JSON. Basado en el conjunto de datos paraloq/json_data_extraction, esta tarea prueba la capacidad de los modelos para analizar diversos tipos de documentos incluyendo registros m\u00e9dicos, listados de comercio electr\u00f3nico, documentos comerciales, itinerarios de viaje, contenido multimedia, especificaciones tecnol\u00f3gicas e informes de manufactura. La evaluaci\u00f3n se enfoca en la precisi\u00f3n del modelo para extraer toda la informaci\u00f3n disponible mientras se adhiere a esquemas JSON proporcionados, probando tanto la comprensi\u00f3n como las capacidades de generaci\u00f3n de salida estructurada en m\u00faltiples dominios.",
      "long_description_pt": "Paraloq avalia as capacidades dos sistemas de IA para extrair informa\u00e7\u00f5es estruturadas de texto n\u00e3o estruturado e retorn\u00e1-las em formato JSON. Baseado no conjunto de dados paraloq/json_data_extraction, esta tarefa testa a capacidade dos modelos de analisar diversos tipos de documentos incluindo registros m\u00e9dicos, listagens de e-commerce, documentos comerciais, itiner\u00e1rios de viagem, conte\u00fado de m\u00eddia, especifica\u00e7\u00f5es tecnol\u00f3gicas e relat\u00f3rios de manufatura. A avalia\u00e7\u00e3o foca na precis\u00e3o do modelo para extrair toda a informa\u00e7\u00e3o dispon\u00edvel enquanto adere a esquemas JSON fornecidos, testando tanto a compreens\u00e3o quanto as capacidades de gera\u00e7\u00e3o de sa\u00edda estruturada em m\u00faltiplos dom\u00ednios.",
      "fewshot": 0,
      "URL": "https://huggingface.co/datasets/paraloq/json_data_extraction"
    }
  }
}
