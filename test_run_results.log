nohup: ignoring input
âœ… Using default vLLM version from main project environment
2025-10-09 17:45:08 | INFO     | benchy.logging       | Logging initialized - log file: logs/benchy_HuggingFaceH4_zephyr-7b-beta_20251009_174508.log
2025-10-09 17:45:08 | INFO     | benchy.logging       | Model: HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:45:08 | INFO     | benchy.logging       | Tasks: unknown
2025-10-09 17:45:08 | INFO     | __main__             | File logging enabled - log file: logs/benchy_HuggingFaceH4_zephyr-7b-beta_20251009_174508.log
2025-10-09 17:45:08 | INFO     | benchy.config        | === Configuration ===
2025-10-09 17:45:08 | INFO     | benchy.config        | Model Name: HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:45:08 | INFO     | benchy.config        | Model dtype: N/A
2025-10-09 17:45:08 | INFO     | benchy.config        | Max model length: 8192
2025-10-09 17:45:08 | INFO     | benchy.config        | GPU memory utilization: 0.95
2025-10-09 17:45:08 | INFO     | benchy.config        | Host: 0.0.0.0
2025-10-09 17:45:08 | INFO     | benchy.config        | Port: 20502
2025-10-09 17:45:08 | INFO     | benchy.config        | CUDA devices: N/A
2025-10-09 17:45:08 | INFO     | benchy.config        | Tensor parallel size: 1
2025-10-09 17:45:08 | INFO     | benchy.config        | Max concurrent sequences: 256
2025-10-09 17:45:08 | INFO     | benchy.config        | Max batched tokens: 8192
2025-10-09 17:45:08 | INFO     | benchy.config        | Tasks: ['translation']
2025-10-09 17:45:08 | INFO     | benchy.config        | Task defaults overrides: {'log_samples': True, 'cuda_devices': '2'}
2025-10-09 17:45:08 | INFO     | benchy.config        | === End Configuration ===
2025-10-09 17:45:08 | INFO     | __main__             | Using task defaults from config: {'log_samples': True, 'cuda_devices': '2'}
2025-10-09 17:45:08 | INFO     | __main__             | Final task defaults overrides: {'log_samples': True, 'cuda_devices': '2'}
2025-10-09 17:45:08 | INFO     | __main__             | Model: HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:45:08 | INFO     | __main__             | Tasks to run: ['translation']
2025-10-09 17:45:08 | INFO     | __main__             | vLLM server: 0.0.0.0:20502
2025-10-09 17:45:08 | INFO     | __main__             | Running pipeline
2025-10-09 17:45:08 | INFO     | httpx                | HTTP Request: GET http://localhost:4200/api/admin/version "HTTP/1.1 200 OK"
2025-10-09 17:45:08 | INFO     | httpx                | HTTP Request: GET http://localhost:4200/api/csrf-token?client=b97c73c5-e9d9-47d7-89cd-a4ea952c5171 "HTTP/1.1 422 Unprocessable Entity"
2025-10-09 17:45:08 | INFO     | httpx                | HTTP Request: POST http://localhost:4200/api/flows/ "HTTP/1.1 200 OK"
2025-10-09 17:45:08 | INFO     | httpx                | HTTP Request: POST http://localhost:4200/api/flow_runs/ "HTTP/1.1 201 Created"
2025-10-09 17:45:08 | INFO     | httpx                | HTTP Request: POST http://localhost:4200/api/flow_runs/9513e721-0ba7-4b4c-b361-59704e6c2833/set_state "HTTP/1.1 201 Created"
2025-10-09 17:45:08 | INFO     | httpx                | HTTP Request: GET http://localhost:4200/api/flow_runs/9513e721-0ba7-4b4c-b361-59704e6c2833 "HTTP/1.1 200 OK"
2025-10-09 17:45:08 | INFO     | prefect.flow_runs    | Beginning flow run 'celadon-alligator' for flow 'benchmark-pipeline'
2025-10-09 17:45:08 | INFO     | prefect.flow_runs    | View at http://localhost:4200/runs/flow-run/9513e721-0ba7-4b4c-b361-59704e6c2833
2025-10-09 17:45:08 | INFO     | src.pipeline         | Starting vLLM benchmark pipeline for model: HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:45:08 | INFO     | src.pipeline         | Tasks to run: ['translation']
2025-10-09 17:45:08 | INFO     | src.pipeline         | Auto-generated run_id: 20251009_174508
2025-10-09 17:45:09 | INFO     | src.gpu_config       | Validating GPU configuration...
2025-10-09 17:45:09 | INFO     | src.gpu_config       | GPU configuration validated successfully
2025-10-09 17:45:09 | INFO     | src.gpu_config       | vLLM will use GPUs: 3
2025-10-09 17:45:09 | INFO     | src.gpu_config       | Tasks will use GPUs: 2
2025-10-09 17:45:09 | INFO     | src.pipeline         | GPU Configuration: {'vllm_devices': '3', 'task_devices': '2', 'vllm_gpu_count': 1, 'task_gpu_count': 1, 'validation': {'check_gpu_availability': True, 'allow_overlap': False}}
2025-10-09 17:45:09 | INFO     | src.generation_config | Fetching generation_config.json for HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:45:09 | INFO     | src.generation_config | Successfully loaded generation_config.json for HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:45:09 | INFO     | src.pipeline         | Run configuration written to: /home/mauro/dev/benchy/outputs/benchmark_outputs/20251009_174508/zephyr-7b-beta/run_config.yaml
2025-10-09 17:45:09 | INFO     | src.pipeline         | Starting vLLM server with CUDA devices: 3
2025-10-09 17:45:09 | INFO     | src.inference.vllm_server | Starting vLLM server for model: HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:45:09 | INFO     | src.inference.vllm_server | No vLLM version specified, using main project environment
âœ… Using default vLLM version from main project environment
2025-10-09 17:45:09 | INFO     | src.inference.vllm_server | Checking for existing vLLM processes with model: HuggingFaceH4/zephyr-7b-beta or port: 20502
2025-10-09 17:45:09 | INFO     | httpx                | HTTP Request: GET http://localhost:4200/api/flows/b75ac7c0-59d7-4876-bec6-5f8945072c49 "HTTP/1.1 200 OK"
2025-10-09 17:45:09 | INFO     | src.inference.vllm_server | No existing vLLM processes found
2025-10-09 17:45:09 | INFO     | benchy.vllm_server   | === Starting vLLM Server ===
2025-10-09 17:45:09 | INFO     | benchy.vllm_server   | Model: HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:45:09 | INFO     | benchy.vllm_server   | Host: 0.0.0.0, Port: 20502
2025-10-09 17:45:09 | INFO     | benchy.vllm_server   | Tensor parallel size: 1
2025-10-09 17:45:09 | INFO     | benchy.vllm_server   | Max model length: 8192
2025-10-09 17:45:09 | INFO     | src.inference.vllm_server | Executing command: CUDA_VISIBLE_DEVICES=3 python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --model HuggingFaceH4/zephyr-7b-beta --port 20502 -tp 1 --max-model-len 8192 --gpu-memory-utilization 0.95 --limit-mm-per-prompt '{"images": 0, "audios": 0}' --enforce-eager --max-num-seqs 256 --max-num-batched-tokens 8192
2025-10-09 17:45:09 | INFO     | benchy.vllm_server   | Command: CUDA_VISIBLE_DEVICES=3 python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --model HuggingFaceH4/zephyr-7b-beta --port 20502 -tp 1 --max-model-len 8192 --gpu-memory-utilization 0.95 --limit-mm-per-prompt '{"images": 0, "audios": 0}' --enforce-eager --max-num-seqs 256 --max-num-batched-tokens 8192
2025-10-09 17:45:09 | INFO     | src.inference.vllm_server | Waiting for vLLM server to start at http://0.0.0.0:20502...
2025-10-09 17:45:09 | INFO     | src.inference.vllm_server | Timeout set to 900 seconds (15 minutes)
2025-10-09 17:45:11 | INFO     | httpx                | HTTP Request: GET http://localhost:4200/api/csrf-token?client=d17ad005-5bf9-44ed-91fe-e5fe5054466a "HTTP/1.1 422 Unprocessable Entity"
2025-10-09 17:45:11 | INFO     | httpx                | HTTP Request: POST http://localhost:4200/api/logs/ "HTTP/1.1 201 Created"
INFO 10-09 17:45:15 [__init__.py:216] Automatically detected platform cuda.
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:45:17 [api_server.py:1896] vLLM API server version 0.10.2
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:45:17 [utils.py:328] non-default args: {'host': '0.0.0.0', 'port': 20502, 'model': 'HuggingFaceH4/zephyr-7b-beta', 'max_model_len': 8192, 'enforce_eager': True, 'gpu_memory_utilization': 0.95, 'limit_mm_per_prompt': {'images': 0, 'audios': 0}, 'max_num_batched_tokens': 8192, 'max_num_seqs': 256}
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:45:27 [__init__.py:742] Resolved architecture: MistralForCausalLM
[1;36m(APIServer pid=2228954)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:45:27 [__init__.py:1815] Using max model len 8192
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:45:28 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:45:28 [__init__.py:3400] Cudagraph is disabled under eager mode
INFO 10-09 17:45:33 [__init__.py:216] Automatically detected platform cuda.
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:45:34 [core.py:654] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:45:34 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='HuggingFaceH4/zephyr-7b-beta', speculative_config=None, tokenizer='HuggingFaceH4/zephyr-7b-beta', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=HuggingFaceH4/zephyr-7b-beta, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[W1009 17:45:37.003517644 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:45:37 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_DP0 pid=2229332)[0;0m WARNING 10-09 17:45:37 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:45:37 [gpu_model_runner.py:2338] Starting to load model HuggingFaceH4/zephyr-7b-beta...
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:45:38 [gpu_model_runner.py:2370] Loading model from scratch...
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:45:38 [cuda.py:362] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:45:39 [weight_utils.py:348] Using model weights format ['*.safetensors']
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/8 [00:00<?, ?it/s]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards:  12% Completed | 1/8 [00:00<00:05,  1.22it/s]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards:  25% Completed | 2/8 [00:02<00:07,  1.33s/it]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards:  38% Completed | 3/8 [00:04<00:07,  1.48s/it]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards:  50% Completed | 4/8 [00:06<00:07,  1.84s/it]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards:  62% Completed | 5/8 [00:09<00:06,  2.20s/it]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards:  75% Completed | 6/8 [00:16<00:07,  3.97s/it]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards:  88% Completed | 7/8 [00:19<00:03,  3.47s/it]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:20<00:00,  2.89s/it]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m Loading safetensors checkpoint shards: 100% Completed | 8/8 [00:20<00:00,  2.61s/it]
[1;36m(EngineCore_DP0 pid=2229332)[0;0m 
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:46:00 [default_loader.py:268] Loading weights took 20.99 seconds
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:46:01 [gpu_model_runner.py:2392] Model loading took 13.4967 GiB and 22.255024 seconds
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:46:05 [gpu_worker.py:298] Available KV cache memory: 8.03 GiB
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:46:05 [kv_cache_utils.py:864] GPU KV cache size: 65,744 tokens
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:46:05 [kv_cache_utils.py:868] Maximum concurrency for 8,192 tokens per request: 8.01x
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:46:05 [gpu_worker.py:391] Free memory on device (23.27/23.57 GiB) on startup. Desired GPU memory utilization is (0.95, 22.39 GiB). Actual usage is 13.5 GiB for weight, 0.85 GiB for peak activation, 0.02 GiB for non-torch memory, and 0.0 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=8461679001` to fit into requested memory, or `--kv-cache-memory=9407111168` to fully utilize gpu memory. Current kv cache memory in use is 8618965401 bytes.
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:46:05 [core.py:218] init engine (profile, create kv cache, warmup model) took 4.21 seconds
[1;36m(EngineCore_DP0 pid=2229332)[0;0m INFO 10-09 17:46:06 [__init__.py:3400] Cudagraph is disabled under eager mode
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:06 [loggers.py:142] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 4109
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:06 [async_llm.py:180] Torch profiler disabled. AsyncLLM CPU traces will not be collected.
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:06 [api_server.py:1692] Supported_tasks: ['generate']
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [api_server.py:1971] Starting vLLM API server 0 on http://0.0.0.0:20502
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:36] Available routes are:
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /openapi.json, Methods: GET, HEAD
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /docs, Methods: GET, HEAD
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /docs/oauth2-redirect, Methods: GET, HEAD
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /redoc, Methods: GET, HEAD
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /health, Methods: GET
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /load, Methods: GET
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /ping, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /ping, Methods: GET
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /version, Methods: GET
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /pooling, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /classify, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /score, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /rerank, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /invocations, Methods: POST
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:07 [launcher.py:44] Route: /metrics, Methods: GET
[1;36m(APIServer pid=2228954)[0;0m INFO:     Started server process [2228954]
[1;36m(APIServer pid=2228954)[0;0m INFO:     Waiting for application startup.
[1;36m(APIServer pid=2228954)[0;0m INFO:     Application startup complete.
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:50522 - "GET /health HTTP/1.1" 200 OK
2025-10-09 17:46:09 | INFO     | src.inference.vllm_server | âœ… vLLM server is ready!
2025-10-09 17:46:09 | INFO     | benchy.vllm_server   | vLLM server started successfully
2025-10-09 17:46:09 | INFO     | prefect.task_runs    | Finished in state Completed()
2025-10-09 17:46:09 | INFO     | src.inference.vllm_server | Testing vLLM API at http://0.0.0.0:20502
2025-10-09 17:46:09 | INFO     | benchy.api_test      | === Testing vLLM API ===
2025-10-09 17:46:09 | INFO     | benchy.api_test      | Server URL: http://0.0.0.0:20502
2025-10-09 17:46:09 | INFO     | benchy.api_test      | Model: HuggingFaceH4/zephyr-7b-beta
[1;36m(EngineCore_DP0 pid=2229332)[0;0m WARNING 10-09 17:46:10 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
2025-10-09 17:46:11 | INFO     | httpx                | HTTP Request: POST http://localhost:4200/api/logs/ "HTTP/1.1 201 Created"
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:50538 - "POST /v1/completions HTTP/1.1" 200 OK
2025-10-09 17:46:11 | INFO     | src.inference.vllm_server | âœ… API test successful!
2025-10-09 17:46:11 | INFO     | benchy.api_test      | API test completed successfully
2025-10-09 17:46:11 | INFO     | benchy.api_test      | Response: {'id': 'cmpl-936675296ffd4525b08fe579d8d4a85b', 'object': 'text_completion', 'created': 1760031969, 'model': 'HuggingFaceH4/zephyr-7b-beta', 'choices': [{'index': 0, 'text': '\n\nIâ€™m still alive and kicking, for those of you who care. I have been travelling quite a bit lately and as such, I havenâ€™t been able to write as much as I would like. I have been keeping a travel', 'logprobs': None, 'finish_reason': 'length', 'stop_reason': None, 'token_ids': None, 'prompt_logprobs': None, 'prompt_token_ids': None}], 'service_tier': None, 'system_fingerprint': None, 'usage': {'prompt_tokens': 7, 'total_tokens': 57, 'completion_tokens': 50, 'prompt_tokens_details': None}, 'kv_transfer_params': None}
2025-10-09 17:46:11 | INFO     | prefect.task_runs    | Finished in state Completed()
2025-10-09 17:46:11 | INFO     | src.generation_config | Saved generation_config.json to /home/mauro/dev/benchy/outputs/benchmark_outputs/20251009_174508/zephyr-7b-beta/generation_config.json
2025-10-09 17:46:11 | INFO     | src.pipeline         | Running translation language evaluation...
2025-10-09 17:46:11 | INFO     | src.config_manager   | Applying task defaults overrides for translation: {'log_samples': True, 'cuda_devices': '2'}
2025-10-09 17:46:11 | INFO     | benchy.config        | === Task Configuration: translation ===
2025-10-09 17:46:11 | INFO     | benchy.config        | Task name: translation
2025-10-09 17:46:11 | INFO     | benchy.config        | Description: Translation evaluation using lm-evaluation-harness
2025-10-09 17:46:11 | INFO     | benchy.config        | LM Eval path: /home/mauro/dev/benchy/external/lm-evaluation-harness
2025-10-09 17:46:11 | INFO     | benchy.config        | Tokenizer backend: huggingface
2025-10-09 17:46:11 | INFO     | benchy.config        | Task defaults:
2025-10-09 17:46:11 | INFO     | benchy.config        |   batch_size: 10
2025-10-09 17:46:11 | INFO     | benchy.config        |   log_samples: True
2025-10-09 17:46:11 | INFO     | benchy.config        |   cache_requests: True
2025-10-09 17:46:11 | INFO     | benchy.config        |   trust_remote_code: False
2025-10-09 17:46:11 | INFO     | benchy.config        |   num_concurrent: 20
2025-10-09 17:46:11 | INFO     | benchy.config        |   max_length: 2048
2025-10-09 17:46:11 | INFO     | benchy.config        |   cuda_devices: 2
2025-10-09 17:46:11 | INFO     | benchy.config        | Output subdirectory: translation
2025-10-09 17:46:11 | INFO     | benchy.config        | === End Task Configuration: translation ===
2025-10-09 17:46:11 | INFO     | src.tasks.lm_harness | Starting Spanish evaluation for model: HuggingFaceH4/zephyr-7b-beta, tasks: translation
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | === Starting Spanish LM Evaluation ===
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | Model: HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | Tasks: translation
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | Server URL: http://0.0.0.0:20502
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | Batch size: 10
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | Concurrent requests: 20
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | Using generation config: {'_from_model_config': True, 'bos_token_id': 1, 'eos_token_id': 2, 'transformers_version': '4.35.0'}
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | Note: vLLM supports batched requests with varying sequence lengths
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | Limit: 10 (testing mode)
2025-10-09 17:46:11 | INFO     | src.tasks.lm_harness | Executing command: lm_eval --model local-completions --model_args model=HuggingFaceH4/zephyr-7b-beta,max_length=2048,base_url=http://0.0.0.0:20502/v1/completions,num_concurrent=20,max_retries=3,tokenized_requests=False,tokenizer_backend=huggingface --tasks translation --batch_size 10 --output_path /home/mauro/dev/benchy/outputs/benchmark_outputs/20251009_174508/zephyr-7b-beta/translation --log_samples --limit 10 --cache_requests true
2025-10-09 17:46:11 | INFO     | benchy.lm_eval       | Full command: lm_eval --model local-completions --model_args model=HuggingFaceH4/zephyr-7b-beta,max_length=2048,base_url=http://0.0.0.0:20502/v1/completions,num_concurrent=20,max_retries=3,tokenized_requests=False,tokenizer_backend=huggingface --tasks translation --batch_size 10 --output_path /home/mauro/dev/benchy/outputs/benchmark_outputs/20251009_174508/zephyr-7b-beta/translation --log_samples --limit 10 --cache_requests true
2025-10-09 17:46:11 | INFO     | src.tasks.lm_harness | Tasks will use GPU(s): 2
2025-10-09 17:46:13 | INFO     | httpx                | HTTP Request: POST http://localhost:4200/api/logs/ "HTTP/1.1 201 Created"
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:18 [loggers.py:123] Engine 000: Avg prompt throughput: 0.6 tokens/s, Avg generation throughput: 4.4 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval] /home/mauro/dev/benchy/external/lm-evaluation-harness/.venv/lib/python3.12/site-packages/torchmetrics/utilities/imports.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval] /home/mauro/dev/benchy/external/lm-evaluation-harness/.venv/lib/python3.12/site-packages/torchmetrics/utilities/imports.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval]   from pkg_resources import DistributionNotFound, get_distribution
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval]   from pkg_resources import DistributionNotFound, get_distribution
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval] The tag 'teleia' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval] The tag 'teleia' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval] Selected Tasks: ['translation']
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval] Selected Tasks: ['translation']
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval] Initializing local-completions model, with arguments: {'model': 'HuggingFaceH4/zephyr-7b-beta', 'max_length': 2048, 'base_url':
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval] Initializing local-completions model, with arguments: {'model': 'HuggingFaceH4/zephyr-7b-beta', 'max_length': 2048, 'base_url':
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval]         'http://0.0.0.0:20502/v1/completions', 'num_concurrent': 20, 'max_retries': 3, 'tokenized_requests': False, 'tokenizer_backend':
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval]         'http://0.0.0.0:20502/v1/completions', 'num_concurrent': 20, 'max_retries': 3, 'tokenized_requests': False, 'tokenizer_backend':
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval]         'huggingface'}
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval]         'huggingface'}
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval] Batch size > 1 detected. Ensure your API supports batched requests with varying total sequence lengths.
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval] Batch size > 1 detected. Ensure your API supports batched requests with varying total sequence lengths.
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval] Using max length 2048 - 1
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval] Using max length 2048 - 1
2025-10-09 17:46:18 | INFO     | src.tasks.lm_harness | [lm_eval] Using tokenizer huggingface
2025-10-09 17:46:18 | INFO     | benchy.lm_eval       | [lm_eval] Using tokenizer huggingface
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:46:28 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] flores_ita_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] flores_ita_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] flores_hin_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] flores_hin_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] flores_fra_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] flores_fra_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] flores_eng_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] flores_eng_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] flores_deu_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] flores_deu_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:36 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:36 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] flores_cmn_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] flores_cmn_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] flores_arb_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] flores_arb_por: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] flores_por_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] flores_por_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] flores_ita_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] flores_ita_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] flores_hin_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] flores_hin_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:37 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:37 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] flores_fra_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] flores_fra_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] flores_eng_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] flores_eng_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] flores_deu_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] flores_deu_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] flores_cmn_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] flores_cmn_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] flores_arb_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] flores_arb_spa: Custom kwargs can be passed to `--metadata` in console (as json string) or to the TaskManager.
2025-10-09 17:47:38 | INFO     | src.tasks.lm_harness | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:38 | INFO     | benchy.lm_eval       | [lm_eval] For example --metadata='{"max_seq_lengths":[4096, 8192]}'. For details see task Readme.
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_arb_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_arb_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_cmn_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_cmn_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_deu_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_deu_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_eng_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_eng_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_fra_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_fra_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_hin_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_hin_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_ita_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_ita_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_por_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_por_spa: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_arb_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_arb_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_cmn_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_cmn_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_deu_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_deu_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_eng_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_eng_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_fra_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_fra_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_hin_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_hin_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] flores_ita_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] flores_ita_por: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\n', 'Translation:'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 250}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] opus_100_en-es: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\nEnglish', '\n\nSpanish', '\n\n"'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 100}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] opus_100_en-es: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\nEnglish', '\n\nSpanish', '\n\n"'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 100}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] opus_100_en-pt: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\nEnglish', '\n\nSpanish', '\n\n"'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 100}
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] opus_100_en-pt: Using gen_kwargs: {'until': ['<|endoftext|>', '</s>', '\n\nTranslate', '\n\nEnglish', '\n\nSpanish', '\n\n"'], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 100}
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Running generate_until requests
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Running generate_until requests
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Tokenized requests are disabled. Context + generation length is not checked.
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Tokenized requests are disabled. Context + generation length is not checked.
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for ita_por dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for ita_por dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for ita_por devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for ita_por devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for hin_por dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for hin_por dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for hin_por devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for hin_por devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for fra_por dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for fra_por dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for fra_por devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for fra_por devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for eng_por dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for eng_por dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for eng_por devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for eng_por devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for deu_por dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for deu_por dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for deu_por devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for deu_por devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for cmn_por dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for cmn_por dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for cmn_por devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for cmn_por devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for arb_por dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for arb_por dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for arb_por devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for arb_por devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for por_spa dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for por_spa dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for por_spa devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for por_spa devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for ita_spa dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for ita_spa dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for ita_spa devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for ita_spa devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for hin_spa dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for hin_spa dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for hin_spa devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for hin_spa devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for fra_spa dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for fra_spa dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for fra_spa devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for fra_spa devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for eng_spa dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for eng_spa dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for eng_spa devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for eng_spa devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for deu_spa dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for deu_spa dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for deu_spa devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for deu_spa devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for cmn_spa dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for cmn_spa dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for cmn_spa devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for cmn_spa devtest split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 1994 translation pairs for arb_spa dev split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 1994 translation pairs for arb_spa dev split
2025-10-09 17:47:39 | INFO     | src.tasks.lm_harness | [lm_eval] Loaded 2024 translation pairs for arb_spa devtest split
2025-10-09 17:47:39 | INFO     | benchy.lm_eval       | [lm_eval] Loaded 2024 translation pairs for arb_spa devtest split
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57552 - "POST /v1/completions HTTP/1.1" 200 OK
2025-10-09 17:47:46 | INFO     | src.tasks.lm_harness | [lm_eval] Requesting API:   0%|          | 0/15 [00:00<?, ?it/s]
2025-10-09 17:47:46 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:   0%|          | 0/15 [00:00<?, ?it/s]
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:47:48 [loggers.py:123] Engine 000: Avg prompt throughput: 1374.6 tokens/s, Avg generation throughput: 811.1 tokens/s, Running: 94 reqs, Waiting: 0 reqs, GPU KV cache usage: 24.2%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57484 - "POST /v1/completions HTTP/1.1" 200 OK
2025-10-09 17:47:49 | INFO     | src.tasks.lm_harness | [lm_eval] Requesting API:   7%|â–‹         | 1/15 [00:07<01:46,  7.64s/it]
2025-10-09 17:47:49 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:   7%|â–‹         | 1/15 [00:07<01:46,  7.64s/it]
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57432 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57434 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57436 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57450 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57466 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57474 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57482 - "POST /v1/completions HTTP/1.1" 200 OK
2025-10-09 17:47:50 | INFO     | src.tasks.lm_harness | [lm_eval] Requesting API:  13%|â–ˆâ–Ž        | 2/15 [00:10<00:59,  4.60s/it]
2025-10-09 17:47:50 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  13%|â–ˆâ–Ž        | 2/15 [00:10<00:59,  4.60s/it]
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57488 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57496 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57512 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57526 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57542 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:57566 - "POST /v1/completions HTTP/1.1" 200 OK
2025-10-09 17:47:50 | INFO     | src.tasks.lm_harness | [lm_eval] Requesting API:  20%|â–ˆâ–ˆ        | 3/15 [00:10<00:33,  2.80s/it]
2025-10-09 17:47:50 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  20%|â–ˆâ–ˆ        | 3/15 [00:10<00:33,  2.80s/it]
2025-10-09 17:47:50 | INFO     | src.tasks.lm_harness | [lm_eval] Requesting API: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]
2025-10-09 17:47:50 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:10<00:00,  1.39it/s]
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:35910 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=2228954)[0;0m INFO:     127.0.0.1:35924 - "POST /v1/completions HTTP/1.1" 200 OK
2025-10-09 17:47:53 | INFO     | src.tasks.lm_harness | [lm_eval] Requesting API:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:47:53 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:47:53 | INFO     | src.tasks.lm_harness | [lm_eval] Requesting API:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.48s/it]
2025-10-09 17:47:53 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.48s/it]
2025-10-09 17:47:53 | INFO     | src.tasks.lm_harness | [lm_eval] Requesting API: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.74s/it]
2025-10-09 17:47:53 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:03<00:00,  1.74s/it]
2025-10-09 17:47:53 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:47:53 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:47:56 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:47:56 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:47:56 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.01it/s]
2025-10-09 17:47:56 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.01it/s]
2025-10-09 17:47:56 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.01it/s]
2025-10-09 17:47:56 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.01it/s]
2025-10-09 17:47:56 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:47:56 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:47:58 [loggers.py:123] Engine 000: Avg prompt throughput: 83.2 tokens/s, Avg generation throughput: 430.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
2025-10-09 17:47:58 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:47:58 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:47:58 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.29it/s]
2025-10-09 17:47:58 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.29it/s]
2025-10-09 17:47:58 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.28it/s]
2025-10-09 17:47:58 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.28it/s]
2025-10-09 17:47:58 | INFO     | src.tasks.lm_harness | [lm_eval] Loading COMET model: Unbabel/wmt22-comet-da
2025-10-09 17:47:58 | INFO     | benchy.lm_eval       | [lm_eval] Loading COMET model: Unbabel/wmt22-comet-da
2025-10-09 17:47:59 | INFO     | src.tasks.lm_harness | [lm_eval] Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
2025-10-09 17:47:59 | INFO     | benchy.lm_eval       | [lm_eval] Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]
2025-10-09 17:47:59 | INFO     | src.tasks.lm_harness | [lm_eval] Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 7394.75it/s]
2025-10-09 17:47:59 | INFO     | benchy.lm_eval       | [lm_eval] Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 7394.75it/s]
2025-10-09 17:48:02 | INFO     | src.tasks.lm_harness | [lm_eval] Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../../mnt/Hiksemi-2Tb/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
2025-10-09 17:48:02 | INFO     | benchy.lm_eval       | [lm_eval] Lightning automatically upgraded your loaded checkpoint from v1.8.3.post1 to v2.5.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../../mnt/Hiksemi-2Tb/.cache/huggingface/hub/models--Unbabel--wmt22-comet-da/snapshots/2760a223ac957f30acfb18c8aa649b01cf1d75f2/checkpoints/model.ckpt`
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:48:08 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
2025-10-09 17:48:12 | INFO     | src.tasks.lm_harness | [lm_eval] Encoder model frozen.
2025-10-09 17:48:12 | INFO     | benchy.lm_eval       | [lm_eval] Encoder model frozen.
2025-10-09 17:48:12 | INFO     | src.tasks.lm_harness | [lm_eval] /home/mauro/dev/benchy/external/lm-evaluation-harness/.venv/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
2025-10-09 17:48:12 | INFO     | benchy.lm_eval       | [lm_eval] /home/mauro/dev/benchy/external/lm-evaluation-harness/.venv/lib/python3.12/site-packages/pytorch_lightning/core/saving.py:195: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']
2025-10-09 17:48:12 | INFO     | src.tasks.lm_harness | [lm_eval] COMET model loaded successfully (CPU-only mode)
2025-10-09 17:48:12 | INFO     | benchy.lm_eval       | [lm_eval] COMET model loaded successfully (CPU-only mode)
2025-10-09 17:48:13 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:48:13 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:48:13 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:48:13 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:48:13 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:48:13 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:48:13 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:48:13 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:48:13 | INFO     | src.tasks.lm_harness | [lm_eval] You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-10-09 17:48:13 | INFO     | benchy.lm_eval       | [lm_eval] You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-10-09 17:48:13 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:48:13 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:48:14 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:14 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:14 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:14 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:14 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:48:14 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:48:14 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.62it/s]
2025-10-09 17:48:14 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.62it/s]
2025-10-09 17:48:14 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.98it/s]
2025-10-09 17:48:14 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.98it/s]
2025-10-09 17:48:14 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.97it/s]
2025-10-09 17:48:14 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  2.97it/s]
2025-10-09 17:48:17 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:48:17 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:48:21 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:21 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:21 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.39it/s]
2025-10-09 17:48:21 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.39it/s]
2025-10-09 17:48:21 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.39it/s]
2025-10-09 17:48:21 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.39it/s]
2025-10-09 17:48:21 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:48:21 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:48:25 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:25 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:25 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.17it/s]
2025-10-09 17:48:25 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.17it/s]
2025-10-09 17:48:25 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.16it/s]
2025-10-09 17:48:25 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.16it/s]
2025-10-09 17:48:26 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:48:26 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:48:26 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:48:26 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:48:26 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:48:26 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:48:26 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:48:26 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:48:26 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:48:26 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:48:27 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:27 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:27 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:27 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:27 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:48:27 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:48:27 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.22it/s]
2025-10-09 17:48:27 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.22it/s]
2025-10-09 17:48:27 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.97it/s]
2025-10-09 17:48:27 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.97it/s]
2025-10-09 17:48:27 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.75it/s]
2025-10-09 17:48:27 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.75it/s]
2025-10-09 17:48:29 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:48:29 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:48:33 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:33 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:33 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]
2025-10-09 17:48:33 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]
2025-10-09 17:48:33 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]
2025-10-09 17:48:33 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.67it/s]
2025-10-09 17:48:34 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:48:34 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:48:38 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:38 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:38 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s]
2025-10-09 17:48:38 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.58it/s]
2025-10-09 17:48:38 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s]
2025-10-09 17:48:38 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.57it/s]
2025-10-09 17:48:38 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:48:38 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:48:38 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:48:38 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:48:38 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:48:38 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:48:38 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:48:38 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:48:38 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:48:38 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:48:39 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:39 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:39 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:39 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:39 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:48:39 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:48:39 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 11.81it/s]
2025-10-09 17:48:39 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 11.81it/s]
2025-10-09 17:48:39 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.65it/s]
2025-10-09 17:48:39 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.65it/s]
2025-10-09 17:48:39 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.61it/s]
2025-10-09 17:48:39 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.61it/s]
2025-10-09 17:48:42 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:48:42 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:48:46 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:46 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:46 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]
2025-10-09 17:48:46 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]
2025-10-09 17:48:46 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]
2025-10-09 17:48:46 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]
2025-10-09 17:48:46 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:48:46 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:48:50 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:50 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:50 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.84it/s]
2025-10-09 17:48:50 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.84it/s]
2025-10-09 17:48:50 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.83it/s]
2025-10-09 17:48:50 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.83it/s]
2025-10-09 17:48:51 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:48:51 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:48:51 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:48:51 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:48:51 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:48:51 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:48:51 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:48:51 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:48:51 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:48:51 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:48:51 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:51 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:51 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:51 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:48:52 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:48:52 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:48:52 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.72it/s]
2025-10-09 17:48:52 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.72it/s]
2025-10-09 17:48:52 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.32it/s]
2025-10-09 17:48:52 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.32it/s]
2025-10-09 17:48:52 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.16it/s]
2025-10-09 17:48:52 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.16it/s]
2025-10-09 17:48:54 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:48:54 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:48:58 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:58 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:48:58 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]
2025-10-09 17:48:58 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]
2025-10-09 17:48:58 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]
2025-10-09 17:48:58 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.63it/s]
2025-10-09 17:48:59 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:48:59 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:49:03 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:03 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:03 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]
2025-10-09 17:49:03 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]
2025-10-09 17:49:03 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]
2025-10-09 17:49:03 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.76it/s]
2025-10-09 17:49:03 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:03 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:03 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:03 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:03 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:03 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:03 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:03 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:03 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:03 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:04 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:04 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:04 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:04 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:04 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:04 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:04 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.12it/s]
2025-10-09 17:49:04 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.12it/s]
2025-10-09 17:49:04 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.56it/s]
2025-10-09 17:49:04 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.56it/s]
2025-10-09 17:49:04 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.45it/s]
2025-10-09 17:49:04 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.45it/s]
2025-10-09 17:49:06 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:49:06 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:49:11 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:11 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:11 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.12it/s]
2025-10-09 17:49:11 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.12it/s]
2025-10-09 17:49:11 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.12it/s]
2025-10-09 17:49:11 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.12it/s]
2025-10-09 17:49:11 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:49:11 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:49:16 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:16 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:16 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.31it/s]
2025-10-09 17:49:16 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.31it/s]
2025-10-09 17:49:16 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.30it/s]
2025-10-09 17:49:16 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.30it/s]
2025-10-09 17:49:16 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:16 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:16 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:16 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:16 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:16 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:16 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:16 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:16 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:16 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:17 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:17 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:17 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:17 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:17 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:17 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:17 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.50it/s]
2025-10-09 17:49:17 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.50it/s]
2025-10-09 17:49:17 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.24it/s]
2025-10-09 17:49:17 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.24it/s]
2025-10-09 17:49:17 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.06it/s]
2025-10-09 17:49:17 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.06it/s]
2025-10-09 17:49:19 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:49:19 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:49:24 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:24 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:24 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]
2025-10-09 17:49:24 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]
2025-10-09 17:49:24 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]
2025-10-09 17:49:24 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.62it/s]
2025-10-09 17:49:24 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:49:24 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:49:28 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:28 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:28 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s]
2025-10-09 17:49:28 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.66it/s]
2025-10-09 17:49:28 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s]
2025-10-09 17:49:28 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.65it/s]
2025-10-09 17:49:29 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:29 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:29 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:29 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:29 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:29 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:29 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:29 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:29 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:29 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:30 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:30 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:30 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:30 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:30 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:30 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:30 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.18it/s]
2025-10-09 17:49:30 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.18it/s]
2025-10-09 17:49:30 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.00it/s]
2025-10-09 17:49:30 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.00it/s]
2025-10-09 17:49:30 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.82it/s]
2025-10-09 17:49:30 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.82it/s]
2025-10-09 17:49:32 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:49:32 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:49:37 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:37 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:37 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]
2025-10-09 17:49:37 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]
2025-10-09 17:49:37 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]
2025-10-09 17:49:37 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.66it/s]
2025-10-09 17:49:37 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:49:37 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:49:41 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:41 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:41 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.74it/s]
2025-10-09 17:49:41 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.74it/s]
2025-10-09 17:49:41 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.73it/s]
2025-10-09 17:49:41 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.73it/s]
2025-10-09 17:49:42 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:42 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:42 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:42 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:42 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:42 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:42 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:42 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:42 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:42 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:42 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:42 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:42 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:42 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:42 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:42 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:43 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.29it/s]
2025-10-09 17:49:43 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.29it/s]
2025-10-09 17:49:43 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.09it/s]
2025-10-09 17:49:43 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.09it/s]
2025-10-09 17:49:43 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.88it/s]
2025-10-09 17:49:43 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.88it/s]
2025-10-09 17:49:45 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:49:45 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:49:50 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:50 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:50 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.03it/s]
2025-10-09 17:49:50 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.03it/s]
2025-10-09 17:49:50 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.03it/s]
2025-10-09 17:49:50 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.03it/s]
2025-10-09 17:49:50 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:49:50 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:49:54 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:54 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:49:54 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.04it/s]
2025-10-09 17:49:54 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.04it/s]
2025-10-09 17:49:54 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.03it/s]
2025-10-09 17:49:54 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  6.03it/s]
2025-10-09 17:49:55 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:55 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:49:55 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:55 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:49:55 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:55 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:49:55 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:55 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:49:55 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:55 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:49:56 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:56 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:56 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:56 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:49:56 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:56 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:49:56 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 10.01it/s]
2025-10-09 17:49:56 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 10.01it/s]
2025-10-09 17:49:56 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.80it/s]
2025-10-09 17:49:56 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.80it/s]
2025-10-09 17:49:56 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.78it/s]
2025-10-09 17:49:56 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 10.78it/s]
2025-10-09 17:49:58 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:49:58 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:50:03 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:03 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:03 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.44it/s]
2025-10-09 17:50:03 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.44it/s]
2025-10-09 17:50:03 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.44it/s]
2025-10-09 17:50:03 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.44it/s]
2025-10-09 17:50:03 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:03 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:07 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:07 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:07 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.24it/s]
2025-10-09 17:50:07 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.24it/s]
2025-10-09 17:50:07 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.23it/s]
2025-10-09 17:50:07 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  7.23it/s]
2025-10-09 17:50:08 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:08 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:08 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:08 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:08 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:08 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:08 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:08 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:08 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:50:08 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:50:09 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:09 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:09 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:09 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:09 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:50:09 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:50:09 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.74it/s]
2025-10-09 17:50:09 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.74it/s]
2025-10-09 17:50:09 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.58it/s]
2025-10-09 17:50:09 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.58it/s]
2025-10-09 17:50:09 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.42it/s]
2025-10-09 17:50:09 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.42it/s]
2025-10-09 17:50:11 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:50:11 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:50:16 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:16 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:16 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]
2025-10-09 17:50:16 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]
2025-10-09 17:50:16 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]
2025-10-09 17:50:16 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.76it/s]
2025-10-09 17:50:16 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:16 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:21 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:21 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:21 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.98it/s]
2025-10-09 17:50:21 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.98it/s]
2025-10-09 17:50:21 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.98it/s]
2025-10-09 17:50:21 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.98it/s]
2025-10-09 17:50:21 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:21 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:21 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:21 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:21 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:21 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:21 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:21 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:21 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:50:21 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:50:22 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:22 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:22 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:22 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:22 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:50:22 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:50:22 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.82it/s]
2025-10-09 17:50:22 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.82it/s]
2025-10-09 17:50:22 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.94it/s]
2025-10-09 17:50:22 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.94it/s]
2025-10-09 17:50:22 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.70it/s]
2025-10-09 17:50:22 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.70it/s]
2025-10-09 17:50:24 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:50:24 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:50:29 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:29 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:29 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]
2025-10-09 17:50:29 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]
2025-10-09 17:50:29 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]
2025-10-09 17:50:29 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.77it/s]
2025-10-09 17:50:29 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:29 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:33 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:33 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:33 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.88it/s]
2025-10-09 17:50:33 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.88it/s]
2025-10-09 17:50:33 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.88it/s]
2025-10-09 17:50:33 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.88it/s]
2025-10-09 17:50:34 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:34 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:34 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:34 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:34 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:34 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:34 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:34 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:34 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:50:34 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:50:35 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:35 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:35 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:35 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:35 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:50:35 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:50:35 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 15.89it/s]
2025-10-09 17:50:35 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 15.89it/s]
2025-10-09 17:50:35 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.84it/s]
2025-10-09 17:50:35 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.84it/s]
2025-10-09 17:50:35 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.55it/s]
2025-10-09 17:50:35 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.55it/s]
2025-10-09 17:50:37 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:50:37 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:50:42 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:42 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:42 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]
2025-10-09 17:50:42 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]
2025-10-09 17:50:42 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]
2025-10-09 17:50:42 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.61it/s]
2025-10-09 17:50:42 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:42 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:46 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:46 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:46 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s]
2025-10-09 17:50:46 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s]
2025-10-09 17:50:46 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s]
2025-10-09 17:50:46 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.63it/s]
2025-10-09 17:50:47 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:47 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:47 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:47 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:47 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:47 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:47 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:47 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:47 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:50:47 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:50:47 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:47 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:47 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:47 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:50:47 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:50:47 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:50:48 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.63it/s]
2025-10-09 17:50:48 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 13.63it/s]
2025-10-09 17:50:48 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.34it/s]
2025-10-09 17:50:48 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.34it/s]
2025-10-09 17:50:48 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.15it/s]
2025-10-09 17:50:48 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.15it/s]
2025-10-09 17:50:50 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:50:50 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:50:54 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:54 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:54 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.15it/s]
2025-10-09 17:50:54 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.15it/s]
2025-10-09 17:50:54 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.15it/s]
2025-10-09 17:50:54 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  2.15it/s]
2025-10-09 17:50:55 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:55 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:50:59 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:59 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:50:59 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.38it/s]
2025-10-09 17:50:59 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.38it/s]
2025-10-09 17:50:59 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.37it/s]
2025-10-09 17:50:59 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.37it/s]
2025-10-09 17:50:59 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:59 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:50:59 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:59 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:50:59 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:59 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:50:59 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:59 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:50:59 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:50:59 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:51:00 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:00 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:00 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:00 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:00 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:51:00 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:51:00 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.56it/s]
2025-10-09 17:51:00 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 12.56it/s]
2025-10-09 17:51:00 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.93it/s]
2025-10-09 17:51:00 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.93it/s]
2025-10-09 17:51:00 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.73it/s]
2025-10-09 17:51:00 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 11.73it/s]
2025-10-09 17:51:02 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:51:02 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:51:07 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:07 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:07 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]
2025-10-09 17:51:07 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]
2025-10-09 17:51:07 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]
2025-10-09 17:51:07 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.70it/s]
2025-10-09 17:51:07 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:51:07 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:51:11 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:11 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:11 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.89it/s]
2025-10-09 17:51:11 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.89it/s]
2025-10-09 17:51:11 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.88it/s]
2025-10-09 17:51:11 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.88it/s]
2025-10-09 17:51:11 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:51:11 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:51:11 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:51:11 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:51:11 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:51:11 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:51:11 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:51:11 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:51:11 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:51:11 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:51:12 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:12 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:12 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:12 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:12 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:51:12 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:51:12 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.00it/s]
2025-10-09 17:51:12 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 14.00it/s]
2025-10-09 17:51:12 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.16it/s]
2025-10-09 17:51:12 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 13.16it/s]
2025-10-09 17:51:12 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.98it/s]
2025-10-09 17:51:12 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 12.98it/s]
2025-10-09 17:51:15 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:51:15 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:51:19 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:19 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:19 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.74it/s]
2025-10-09 17:51:19 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.74it/s]
2025-10-09 17:51:19 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.73it/s]
2025-10-09 17:51:19 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.73it/s]
2025-10-09 17:51:19 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:51:19 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:51:23 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:23 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:23 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.98it/s]
2025-10-09 17:51:23 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.98it/s]
2025-10-09 17:51:23 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.96it/s]
2025-10-09 17:51:23 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.96it/s]
2025-10-09 17:51:24 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:51:24 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:51:24 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:51:24 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:51:24 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:51:24 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:51:24 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:51:24 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:51:24 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:51:24 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:51:25 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:25 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:25 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:25 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:25 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:51:25 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:51:25 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 17.30it/s]
2025-10-09 17:51:25 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 17.30it/s]
2025-10-09 17:51:25 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 19.46it/s]
2025-10-09 17:51:25 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 19.46it/s]
2025-10-09 17:51:25 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 19.40it/s]
2025-10-09 17:51:25 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 19.40it/s]
2025-10-09 17:51:27 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:51:27 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: chrf
2025-10-09 17:51:31 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:31 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:31 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.82it/s]
2025-10-09 17:51:31 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.82it/s]
2025-10-09 17:51:31 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.82it/s]
2025-10-09 17:51:31 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  3.82it/s]
2025-10-09 17:51:32 | INFO     | src.tasks.lm_harness | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:51:32 | INFO     | benchy.lm_eval       | [lm_eval] bootstrapping for stddev: bleu
2025-10-09 17:51:36 | INFO     | src.tasks.lm_harness | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:36 | INFO     | benchy.lm_eval       | [lm_eval]   0%|          | 0/1 [00:00<?, ?it/s]
2025-10-09 17:51:36 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.69it/s]
2025-10-09 17:51:36 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.69it/s]
2025-10-09 17:51:36 | INFO     | src.tasks.lm_harness | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.68it/s]
2025-10-09 17:51:36 | INFO     | benchy.lm_eval       | [lm_eval] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.68it/s]
2025-10-09 17:51:36 | INFO     | src.tasks.lm_harness | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:51:36 | INFO     | benchy.lm_eval       | [lm_eval] ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-10-09 17:51:36 | INFO     | src.tasks.lm_harness | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:51:36 | INFO     | benchy.lm_eval       | [lm_eval] GPU available: True (cuda), used: True
2025-10-09 17:51:36 | INFO     | src.tasks.lm_harness | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:51:36 | INFO     | benchy.lm_eval       | [lm_eval] TPU available: False, using: 0 TPU cores
2025-10-09 17:51:36 | INFO     | src.tasks.lm_harness | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:51:36 | INFO     | benchy.lm_eval       | [lm_eval] HPU available: False, using: 0 HPUs
2025-10-09 17:51:36 | INFO     | src.tasks.lm_harness | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:51:36 | INFO     | benchy.lm_eval       | [lm_eval] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [2]
2025-10-09 17:51:37 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:37 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:37 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:37 | INFO     | benchy.lm_eval       | [lm_eval] Predicting: 0it [00:00, ?it/s]
2025-10-09 17:51:37 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:51:37 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
2025-10-09 17:51:37 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 17.77it/s]
2025-10-09 17:51:37 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 17.77it/s]
2025-10-09 17:51:37 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.16it/s]
2025-10-09 17:51:37 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.16it/s]
2025-10-09 17:51:37 | INFO     | src.tasks.lm_harness | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.09it/s]
2025-10-09 17:51:37 | INFO     | benchy.lm_eval       | [lm_eval] Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.09it/s]
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving results aggregated
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving results aggregated
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_arb_por
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_arb_por
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_arb_spa
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_arb_spa
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_cmn_por
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_cmn_por
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_cmn_spa
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_cmn_spa
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_deu_por
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_deu_por
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_deu_spa
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_deu_spa
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_eng_por
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_eng_por
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_eng_spa
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_eng_spa
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_fra_por
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_fra_por
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_fra_spa
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_fra_spa
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_hin_por
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_hin_por
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_hin_spa
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_hin_spa
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_ita_por
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_ita_por
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_ita_spa
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_ita_spa
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: flores_por_spa
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: flores_por_spa
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: opus_100_en-es
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: opus_100_en-es
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] Saving per-sample results for: opus_100_en-pt
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] Saving per-sample results for: opus_100_en-pt
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] local-completions (model=HuggingFaceH4/zephyr-7b-beta,max_length=2048,base_url=http://0.0.0.0:20502/v1/completions,num_concurrent=20,max_retries=3,tokenized_requests=False,tokenizer_backend=huggingface), gen_kwargs: (None), limit: 10.0, num_fewshot: None, batch_size: 10
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] local-completions (model=HuggingFaceH4/zephyr-7b-beta,max_length=2048,base_url=http://0.0.0.0:20502/v1/completions,num_concurrent=20,max_retries=3,tokenized_requests=False,tokenizer_backend=huggingface), gen_kwargs: (None), limit: 10.0, num_fewshot: None, batch_size: 10
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |         Tasks         |Version|     Filter      |n-shot|Metric|   | Value |   |Stderr|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |         Tasks         |Version|     Filter      |n-shot|Metric|   | Value |   |Stderr|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |-----------------------|------:|-----------------|-----:|------|---|------:|---|------|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |-----------------------|------:|-----------------|-----:|------|---|------:|---|------|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |translation            |      1|clean_translation|      |bleu  |â†‘  |20.6390|Â±  |0.9800|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |translation            |      1|clean_translation|      |bleu  |â†‘  |20.6390|Â±  |0.9800|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |45.2689|Â±  |1.1021|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |45.2689|Â±  |1.1021|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.7201|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.7201|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] | - flores_bidirectional|      3|clean_translation|      |bleu  |â†‘  |19.5023|Â±  |0.8968|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] | - flores_bidirectional|      3|clean_translation|      |bleu  |â†‘  |19.5023|Â±  |0.8968|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |44.0460|Â±  |1.1335|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |44.0460|Â±  |1.1335|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.7095|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.7095|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - porâ†”arb            |      3|clean_translation|     0|bleu  |â†‘  | 3.4463|Â±  |1.5740|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - porâ†”arb            |      3|clean_translation|     0|bleu  |â†‘  | 3.4463|Â±  |1.5740|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |16.7423|Â±  |5.4443|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |16.7423|Â±  |5.4443|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.4150|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.4150|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - spaâ†”arb            |      3|clean_translation|     0|bleu  |â†‘  | 2.5172|Â±  |1.3339|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - spaâ†”arb            |      3|clean_translation|     0|bleu  |â†‘  | 2.5172|Â±  |1.3339|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |15.2797|Â±  |5.2880|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |15.2797|Â±  |5.2880|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.3810|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.3810|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - porâ†”cmn            |      3|clean_translation|     0|bleu  |â†‘  |10.5054|Â±  |2.7897|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - porâ†”cmn            |      3|clean_translation|     0|bleu  |â†‘  |10.5054|Â±  |2.7897|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |33.4212|Â±  |6.6118|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |33.4212|Â±  |6.6118|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.6928|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.6928|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - spaâ†”cmn            |      3|clean_translation|     0|bleu  |â†‘  |11.2493|Â±  |3.2717|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - spaâ†”cmn            |      3|clean_translation|     0|bleu  |â†‘  |11.2493|Â±  |3.2717|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |36.5116|Â±  |6.9256|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |36.5116|Â±  |6.9256|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.7584|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.7584|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - porâ†”deu            |      3|clean_translation|     0|bleu  |â†‘  |21.4680|Â±  |3.3719|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - porâ†”deu            |      3|clean_translation|     0|bleu  |â†‘  |21.4680|Â±  |3.3719|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |51.3245|Â±  |3.2460|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |51.3245|Â±  |3.2460|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.7595|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.7595|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - spaâ†”deu            |      3|clean_translation|     0|bleu  |â†‘  |12.5534|Â±  |3.6259|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - spaâ†”deu            |      3|clean_translation|     0|bleu  |â†‘  |12.5534|Â±  |3.6259|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |46.4023|Â±  |2.7122|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |46.4023|Â±  |2.7122|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.7537|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.7537|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - porâ†”eng            |      3|clean_translation|     0|bleu  |â†‘  |48.6857|Â±  |6.8672|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - porâ†”eng            |      3|clean_translation|     0|bleu  |â†‘  |48.6857|Â±  |6.8672|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |68.1793|Â±  |4.7345|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |68.1793|Â±  |4.7345|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8548|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8548|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - spaâ†”eng            |      3|clean_translation|     0|bleu  |â†‘  |31.1603|Â±  |3.5899|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - spaâ†”eng            |      3|clean_translation|     0|bleu  |â†‘  |31.1603|Â±  |3.5899|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |58.6693|Â±  |3.0492|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |58.6693|Â±  |3.0492|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8518|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8518|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - porâ†”fra            |      3|clean_translation|     0|bleu  |â†‘  |39.3470|Â±  |5.5797|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - porâ†”fra            |      3|clean_translation|     0|bleu  |â†‘  |39.3470|Â±  |5.5797|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |63.8294|Â±  |4.9847|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |63.8294|Â±  |4.9847|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8372|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8372|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - spaâ†”fra            |      3|clean_translation|     0|bleu  |â†‘  |26.7165|Â±  |4.2598|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - spaâ†”fra            |      3|clean_translation|     0|bleu  |â†‘  |26.7165|Â±  |4.2598|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |58.0853|Â±  |3.1998|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |58.0853|Â±  |3.1998|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8523|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8523|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - porâ†”hin            |      3|clean_translation|     0|bleu  |â†‘  | 6.0477|Â±  |2.3923|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - porâ†”hin            |      3|clean_translation|     0|bleu  |â†‘  | 6.0477|Â±  |2.3923|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |25.1873|Â±  |4.1823|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |25.1873|Â±  |4.1823|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.5055|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.5055|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - spaâ†”hin            |      3|clean_translation|     0|bleu  |â†‘  | 2.3148|Â±  |1.1636|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - spaâ†”hin            |      3|clean_translation|     0|bleu  |â†‘  | 2.3148|Â±  |1.1636|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |21.7780|Â±  |4.4555|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |21.7780|Â±  |4.4555|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.4826|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.4826|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - porâ†”ita            |      3|clean_translation|     0|bleu  |â†‘  |24.2189|Â±  |1.7067|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - porâ†”ita            |      3|clean_translation|     0|bleu  |â†‘  |24.2189|Â±  |1.7067|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |54.3829|Â±  |1.8693|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |54.3829|Â±  |1.8693|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8287|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8287|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - spaâ†”ita            |      3|clean_translation|     0|bleu  |â†‘  |29.6885|Â±  |2.7824|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - spaâ†”ita            |      3|clean_translation|     0|bleu  |â†‘  |29.6885|Â±  |2.7824|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |57.1506|Â±  |2.5100|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |57.1506|Â±  |2.5100|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8486|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8486|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - spaâ†”por            |      3|clean_translation|     0|bleu  |â†‘  |22.6148|Â±  |2.5761|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - spaâ†”por            |      3|clean_translation|     0|bleu  |â†‘  |22.6148|Â±  |2.5761|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |53.7463|Â±  |2.8227|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |53.7463|Â±  |2.8227|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8206|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8206|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] | - opus                |      1|clean_translation|      |bleu  |â†‘  |29.1643|Â±  |4.9150|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] | - opus                |      1|clean_translation|      |bleu  |â†‘  |29.1643|Â±  |4.9150|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |54.4406|Â±  |3.9360|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |54.4406|Â±  |3.9360|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.8000|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.8000|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - en-es              |      1|clean_translation|     0|bleu  |â†‘  |28.7064|Â±  |5.9367|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - en-es              |      1|clean_translation|     0|bleu  |â†‘  |28.7064|Â±  |5.9367|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |52.5317|Â±  |5.1597|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |52.5317|Â±  |5.1597|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8169|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.8169|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |  - en-pt              |      1|clean_translation|     0|bleu  |â†‘  |29.6222|Â±  |7.8349|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |  - en-pt              |      1|clean_translation|     0|bleu  |â†‘  |29.6222|Â±  |7.8349|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |56.3495|Â±  |5.9452|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|chrf  |â†‘  |56.3495|Â±  |5.9452|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.7830|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|     0|comet |â†‘  | 0.7830|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |        Groups         |Version|     Filter      |n-shot|Metric|   | Value |   |Stderr|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |        Groups         |Version|     Filter      |n-shot|Metric|   | Value |   |Stderr|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |-----------------------|------:|-----------------|------|------|---|------:|---|------|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |-----------------------|------:|-----------------|------|------|---|------:|---|------|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |translation            |      1|clean_translation|      |bleu  |â†‘  |20.6390|Â±  |0.9800|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |translation            |      1|clean_translation|      |bleu  |â†‘  |20.6390|Â±  |0.9800|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |45.2689|Â±  |1.1021|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |45.2689|Â±  |1.1021|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.7201|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.7201|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] | - flores_bidirectional|      3|clean_translation|      |bleu  |â†‘  |19.5023|Â±  |0.8968|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] | - flores_bidirectional|      3|clean_translation|      |bleu  |â†‘  |19.5023|Â±  |0.8968|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |44.0460|Â±  |1.1335|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |44.0460|Â±  |1.1335|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.7095|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.7095|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] | - opus                |      1|clean_translation|      |bleu  |â†‘  |29.1643|Â±  |4.9150|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] | - opus                |      1|clean_translation|      |bleu  |â†‘  |29.1643|Â±  |4.9150|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |54.4406|Â±  |3.9360|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |chrf  |â†‘  |54.4406|Â±  |3.9360|
2025-10-09 17:51:40 | INFO     | src.tasks.lm_harness | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.8000|Â±  |   N/A|
2025-10-09 17:51:40 | INFO     | benchy.lm_eval       | [lm_eval] |                       |       |clean_translation|      |comet |â†‘  | 0.8000|Â±  |   N/A|
2025-10-09 17:51:47 | INFO     | src.tasks.lm_harness | lm_eval completed successfully
2025-10-09 17:51:47 | INFO     | benchy.lm_eval       | === LM Evaluation COMPLETED SUCCESSFULLY ===
2025-10-09 17:51:47 | INFO     | benchy.lm_eval       | Output saved to: /home/mauro/dev/benchy/outputs/benchmark_outputs/20251009_174508/zephyr-7b-beta/translation
2025-10-09 17:51:47 | INFO     | prefect.task_runs    | Finished in state Completed()
2025-10-09 17:51:47 | INFO     | prefect.task_runs    | Finished in state Completed()
2025-10-09 17:51:47 | INFO     | src.inference.vllm_server | Stopping vLLM server (PID: 2228954)
2025-10-09 17:51:47 | INFO     | benchy.vllm_server   | === Stopping vLLM Server (PID: 2228954) ===
[1;36m(APIServer pid=2228954)[0;0m WARNING 10-09 17:51:47 [launcher.py:98] port 20502 is used by process psutil.Process(pid=2228954, name='python', status='running', started='17:45:08') launched with command:
[1;36m(APIServer pid=2228954)[0;0m WARNING 10-09 17:51:47 [launcher.py:98] python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --model HuggingFaceH4/zephyr-7b-beta --port 20502 -tp 1 --max-model-len 8192 --gpu-memory-utilization 0.95 --limit-mm-per-prompt {"images": 0, "audios": 0} --enforce-eager --max-num-seqs 256 --max-num-batched-tokens 8192
[1;36m(APIServer pid=2228954)[0;0m INFO 10-09 17:51:47 [launcher.py:101] Shutting down FastAPI HTTP server.
[rank0]:[W1009 17:51:47.679710972 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(APIServer pid=2228954)[0;0m INFO:     Shutting down
[1;36m(APIServer pid=2228954)[0;0m INFO:     Waiting for application shutdown.
[1;36m(APIServer pid=2228954)[0;0m INFO:     Application shutdown complete.
2025-10-09 17:51:48 | INFO     | src.inference.vllm_server | âœ… vLLM server terminated gracefully
2025-10-09 17:51:48 | INFO     | benchy.vllm_server   | vLLM server terminated gracefully
2025-10-09 17:51:48 | INFO     | prefect.task_runs    | Finished in state Completed()
2025-10-09 17:51:48 | INFO     | src.pipeline         | Benchmark pipeline completed successfully
2025-10-09 17:51:48 | INFO     | httpx                | HTTP Request: POST http://localhost:4200/api/flow_runs/9513e721-0ba7-4b4c-b361-59704e6c2833/set_state "HTTP/1.1 201 Created"
2025-10-09 17:51:48 | INFO     | prefect.flow_runs    | Finished in state Completed()
2025-10-09 17:51:48 | INFO     | __main__             | Benchmark pipeline completed successfully!
2025-10-09 17:51:48 | INFO     | __main__             | Results: {'status': 'success', 'method': 'graceful', 'pid': 2228954}
2025-10-09 17:51:48 | INFO     | benchy.summary       | === RUN SUMMARY ===
2025-10-09 17:51:48 | INFO     | benchy.summary       | Model: HuggingFaceH4/zephyr-7b-beta
2025-10-09 17:51:48 | INFO     | benchy.summary       | Return code: 0
2025-10-09 17:51:48 | INFO     | benchy.summary       | Log file: logs/benchy_HuggingFaceH4_zephyr-7b-beta_20251009_174508.log
2025-10-09 17:51:48 | INFO     | benchy.summary       | Run completed successfully
2025-10-09 17:51:48 | INFO     | benchy.summary       | === END SUMMARY ===
2025-10-09 17:51:48 | INFO     | httpx                | HTTP Request: POST http://localhost:4200/api/logs/ "HTTP/1.1 201 Created"
