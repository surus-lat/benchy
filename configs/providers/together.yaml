# Together AI API Provider Configuration
# OpenAI-compatible API for accessing hosted models

provider_type: together
base_url: "https://api.together.xyz/v1"
api_key_env: "TOGETHER_API_KEY"  # Environment variable to read API key from
timeout: 120
max_retries: 3

# Rate limiting to avoid 429 errors
# Together AI has rate limits, keep concurrent requests low
max_concurrent: 3

# Default generation parameters (can be overridden in model config)
temperature: 0.0
max_tokens: 4096

# Provider capability flags for compatibility checks
capabilities:
  # Together is OpenAI-compatible and supports multimodal + local image paths
  # for models that accept vision inputs. Per-model configs should set
  # `metadata.supports_multimodal` to restrict this for text-only models.
  supports_multimodal: true
  supports_schema: true
  supports_files: true
  supports_logprobs: false
  supports_streaming: false
  request_modes: ["chat", "completions"]
