# Base vLLM configuration for single GPU setup
# This config contains all default values for vLLM server

host: "0.0.0.0"
port: 20501
tensor_parallel_size: 1
max_model_len: 8192
gpu_memory_utilization: 0.7
enforce_eager: true
limit_mm_per_prompt: '{"images": 0, "audios": 0}'
kv_cache_memory: 12934271795
hf_cache: "/mnt/Hiksemi-2Tb/.cache/huggingface"
hf_token: ""
startup_timeout: 900
cuda_devices: "3"
