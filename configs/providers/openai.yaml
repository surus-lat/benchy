# Base OpenAI API configuration
# This config is used for models accessed via OpenAI's API

provider_type: openai
base_url: "https://api.openai.com/v1"
api_key_env: "OPENAI_API_KEY"  # Environment variable to read API key from
timeout: 120
max_retries: 3

# Rate limiting to avoid 429 errors
# Limits concurrent requests (lower = safer but slower)
max_concurrent: 3

# Default generation parameters (can be overridden in model config)
temperature: 1.0

# Parameter name for max tokens (some models like gpt-5-mini use 'max_completion_tokens' instead of 'max_tokens')
# Can be overridden in model config overrides
max_tokens_param_name: "max_tokens"  # Options: "max_tokens" or "max_completion_tokens"

# Provider capability flags for compatibility checks
capabilities:
  supports_multimodal: true
  supports_schema: true
  supports_files: true
  supports_logprobs: false
  supports_streaming: false
  request_modes: ["chat", "completions"]
