model:
  name: "01-ai/Yi-1.5-6B-Chat"

vllm:
  provider_config: "vllm_single_card"
  overrides:
    max_model_len: 4096

tasks:
  - "structured_extraction"
