model:
  name: Qwen/Qwen3-VL-8B-Instruct
vllm:
  provider_config: vllm_two_cards_mm
  overrides:
    kv_cache_memory: 0
    gpu_memory_utilization: 0.90
    port: 20502
    trust_remote_code: true
    timeout: 240
task_defaults:
  log_samples: true
  cuda_devices: '1'
  batch_size: 5
tasks:
- latam_board
metadata:
  max_context_length: 8192
  supports_multimodal: true
  model_type: qwen3_vl
  detected_from_config: true
  generated_at: '2025-10-16T05:14:10.737948'
  gpu_type: two
