vllm:
  host: "0.0.0.0"
  port: 20501
  tensor_parallel_size: 1
  max_model_len: 8192           # Match original working command
  gpu_memory_utilization: 0.7    # Reduced memory utilization to allow for loglikelihood computation
  enforce_eager: true
  limit_mm_per_prompt: '{"images": 0, "audios": 0}'
  hf_cache: "/mnt/Hiksemi-2Tb/.cache/huggingface"
  startup_timeout: 900           # Server startup timeout in seconds (15 minutes)