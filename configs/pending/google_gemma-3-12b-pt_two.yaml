model:
  name: google/gemma-3-12b-pt
vllm:
  provider_config: vllm_two_cards
  overrides:
    kv_cache_memory: 0
    gpu_memory_utilization: 0.95
    port: 20502
    trust_remote_code: true
    limit_mm_per_prompt: '{"images": 0, "audios": 0}'
task_defaults:
  log_samples: true
  cuda_devices: '1'
tasks:
- latam_board
metadata:
  max_context_length: 8192
  is_multimodal: true
  model_type: gemma3
  detected_from_config: true
  generated_at: '2025-10-16T08:54:23.814993'
  gpu_type: two
