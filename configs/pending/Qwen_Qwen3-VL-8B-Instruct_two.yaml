model:
  name: Qwen/Qwen3-VL-8B-Instruct
vllm:
  provider_config: vllm_two_cards
  overrides:
    kv_cache_memory: 0
    gpu_memory_utilization: 0.95
    port: 20502
    trust_remote_code: true
    limit_mm_per_prompt: '{"images": 0, "audios": 0}'
task_defaults:
  log_samples: true
  cuda_devices: '1'
tasks:
- latam_board
metadata:
  max_context_length: 8192
  is_multimodal: true
  model_type: qwen3_vl
  detected_from_config: true
  generated_at: '2025-10-16T05:14:10.737948'
  gpu_type: two
