# Template: cloud model config (OpenAI-compatible)
# Copy to configs/models/<your_model>.yaml and edit.

model:
  name: "gpt-4o-mini"

openai:
  provider_config: openai
  overrides:
    # Model-specific defaults
    temperature: 0.0
    max_tokens: 2048
    # max_tokens_param_name: "max_completion_tokens"
    # max_concurrent: 2

# Defaults applied to all tasks
# (task.json defaults can override these)
task_defaults:
  log_samples: true
  batch_size: 10

# Tasks or task groups
# See configs/config.yaml task_groups for shortcuts like "latam_board"
tasks:
  - "structured_extraction"

# To use Anthropic or Together, swap the provider block above:
# anthropic:
#   provider_config: anthropic
# together:
#   provider_config: together

metadata:
  supports_multimodal: true
  supports_logprobs: false
