nohup: ignoring input
[37mStarting benchy - vLLM-powered ML model benchmarking[0m
[37mLoaded environment variables from .env[0m
[37mLoaded configuration from configs/test-gemma.yaml[0m
[37m✅ ZenML server is already running[0m
2025-09-17 03:23:56 | INFO     | benchy.logging       | Logging initialized - log file: logs/benchy_google_gemma-3n-E4B-it_20250917_032356.log
2025-09-17 03:23:56 | INFO     | benchy.logging       | Model: google/gemma-3n-E4B-it
2025-09-17 03:23:56 | INFO     | benchy.logging       | Tasks: unknown
[37mFile logging enabled - log file: logs/benchy_google_gemma-3n-E4B-it_20250917_032356.log[0m
2025-09-17 03:23:56 | INFO     | benchy.config        | === Configuration ===
2025-09-17 03:23:56 | INFO     | benchy.config        | Model Name: google/gemma-3n-E4B-it
2025-09-17 03:23:56 | INFO     | benchy.config        | Model dtype: N/A
2025-09-17 03:23:56 | INFO     | benchy.config        | Model max_length: N/A
2025-09-17 03:23:56 | INFO     | benchy.config        | Tasks: N/A
2025-09-17 03:23:56 | INFO     | benchy.config        | Device: N/A
2025-09-17 03:23:56 | INFO     | benchy.config        | Batch size: 10
2025-09-17 03:23:56 | INFO     | benchy.config        | Output path: /home/mauro/dev/lm-evaluation-harness/output
2025-09-17 03:23:56 | INFO     | benchy.config        | Log samples: True
2025-09-17 03:23:56 | INFO     | benchy.config        | Limit: 10 (testing mode)
2025-09-17 03:23:56 | INFO     | benchy.config        | LM Eval path: /home/mauro/dev/lm-evaluation-harness
2025-09-17 03:23:56 | INFO     | benchy.config        | Leaderboard path: /home/mauro/dev/leaderboard
2025-09-17 03:23:56 | INFO     | benchy.config        | === End Configuration ===
[37mModel: google/gemma-3n-E4B-it[0m
[37mSpanish tasks: latam_es[0m
[37mPortuguese tasks: latam_pr[0m
[37mvLLM server: 0.0.0.0:8000[0m
[37mRunning pipeline with custom name: TEST_gemma_3n_E4B_it_2025_09_17_03_23_56[0m
[37mTEST run detected - limit set to 10 examples per task[0m
[37mStarting vLLM benchmark pipeline for model: google/gemma-3n-E4B-it[0m
[37mRunning Spanish language evaluation...[0m
[37mRunning Portuguese language evaluation...[0m
[37mBenchmark pipeline completed successfully[0m
[37mInitiating a new run for the pipeline: [0m[38;5;105mbenchmark_pipeline[37m.[0m
[33mIn a future release, the default Python package installer used by ZenML to build container images for your containerized pipelines will change from 'pip' to 'uv'. To maintain current behavior, you can explicitly set [0m[38;5;105mpython_package_installer=PythonPackageInstaller.PIP[33m in your DockerSettings.[0m
[37mUsing user: [0m[38;5;105mdefault[37m[0m
[37mUsing stack: [0m[38;5;105mdefault[37m[0m
[37m  artifact_store: [0m[38;5;105mdefault[37m[0m
[37m  orchestrator: [0m[38;5;105mdefault[37m[0m
[37mDashboard URL for Pipeline Run: [0m[34mhttp://127.0.0.1:8237/projects/default/runs/7493e2f4-45db-4eaf-8db4-8862834b5b29[37m[0m
[37mStep [0m[38;5;105mstart_vllm_server[37m has started.[0m
[start_vllm_server] [37mStarting vLLM server for model: google/gemma-3n-E4B-it[0m
[start_vllm_server] 2025-09-17 03:23:58 | INFO     | benchy.vllm_server   | === Starting vLLM Server ===
[start_vllm_server] 2025-09-17 03:23:58 | INFO     | benchy.vllm_server   | Model: google/gemma-3n-E4B-it
[start_vllm_server] 2025-09-17 03:23:58 | INFO     | benchy.vllm_server   | Host: 0.0.0.0, Port: 8000
[start_vllm_server] 2025-09-17 03:23:58 | INFO     | benchy.vllm_server   | Tensor parallel size: 1
[start_vllm_server] 2025-09-17 03:23:58 | INFO     | benchy.vllm_server   | Max model length: 8192
[start_vllm_server] [37mExecuting command: python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --model google/gemma-3n-E4B-it --port 8000 -tp 1 --max-model-len 8192 --gpu-memory-utilization 0.9 --limit-mm-per-prompt '{"images": 0, "audios": 0}' --enforce-eager[0m
[start_vllm_server] 2025-09-17 03:23:58 | INFO     | benchy.vllm_server   | Command: python -m vllm.entrypoints.openai.api_server --host 0.0.0.0 --model google/gemma-3n-E4B-it --port 8000 -tp 1 --max-model-len 8192 --gpu-memory-utilization 0.9 --limit-mm-per-prompt '{"images": 0, "audios": 0}' --enforce-eager
[start_vllm_server] [37mWaiting for vLLM server to start at [0m[34mhttp://0.0.0.0:8000...[37m[0m
INFO 09-17 03:24:04 [__init__.py:241] Automatically detected platform cuda.
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:24:05 [api_server.py:1805] vLLM API server version 0.10.1.1
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:24:05 [utils.py:326] non-default args: {'host': '0.0.0.0', 'model': 'google/gemma-3n-E4B-it', 'max_model_len': 8192, 'enforce_eager': True, 'limit_mm_per_prompt': {'images': 0, 'audios': 0}}
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:24:18 [__init__.py:711] Resolved architecture: Gemma3nForConditionalGeneration
[1;36m(APIServer pid=296140)[0;0m `torch_dtype` is deprecated! Use `dtype` instead!
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:24:18 [__init__.py:1750] Using max model len 8192
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:24:19 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:24:19 [__init__.py:3565] Cudagraph is disabled under eager mode
INFO 09-17 03:24:31 [__init__.py:241] Automatically detected platform cuda.
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:34 [core.py:636] Waiting for init message from front-end.
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:34 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='google/gemma-3n-E4B-it', speculative_config=None, tokenizer='google/gemma-3n-E4B-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=google/gemma-3n-E4B-it, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:36 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_0 pid=296654)[0;0m WARNING 09-17 03:24:39 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_0 pid=296654)[0;0m Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 27685.17it/s]
[1;36m(EngineCore_0 pid=296654)[0;0m Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Fetching 2 files: 100%|██████████| 2/2 [00:00<00:00, 4171.36it/s]
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:52 [gpu_model_runner.py:1953] Starting to load model google/gemma-3n-E4B-it...
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:53 [gpu_model_runner.py:1985] Loading model from scratch...
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:53 [__init__.py:3565] Cudagraph is disabled under eager mode
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:53 [cuda.py:328] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:54 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(EngineCore_0 pid=296654)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]
[1;36m(EngineCore_0 pid=296654)[0;0m Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.18it/s]
[1;36m(EngineCore_0 pid=296654)[0;0m Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:01<00:01,  1.36it/s]
[1;36m(EngineCore_0 pid=296654)[0;0m Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:02<00:00,  1.26it/s]
[1;36m(EngineCore_0 pid=296654)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.14it/s]
[1;36m(EngineCore_0 pid=296654)[0;0m Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:03<00:00,  1.23it/s]
[1;36m(EngineCore_0 pid=296654)[0;0m 
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:58 [default_loader.py:262] Loading weights took 3.49 seconds
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:59 [gpu_model_runner.py:2007] Model loading took 14.6916 GiB and 4.801267 seconds
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:24:59 [gpu_model_runner.py:2591] Encoder cache will be initialized with a budget of 2048 tokens, and profiled with 7 image items of the maximum feature size.
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:25:02 [gpu_worker.py:276] Available KV cache memory: 4.08 GiB
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:25:02 [kv_cache_utils.py:1013] GPU KV cache size: 106,848 tokens
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:25:02 [kv_cache_utils.py:1017] Maximum concurrency for 8,192 tokens per request: 28.88x
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:25:02 [core.py:214] init engine (profile, create kv cache, warmup model) took 3.63 seconds
[1;36m(EngineCore_0 pid=296654)[0;0m INFO 09-17 03:25:05 [__init__.py:3565] Cudagraph is disabled under eager mode
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:05 [loggers.py:142] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 33391
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:05 [api_server.py:1611] Supported_tasks: ['generate']
[1;36m(APIServer pid=296140)[0;0m WARNING 09-17 03:25:06 [__init__.py:1625] Default sampling parameters have been overridden by the model's Hugging Face generation config recommended from the model creator. If this is not intended, please relaunch vLLM instance with `--generation-config vllm`.
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [serving_responses.py:120] Using default chat sampling params from model: {'top_k': 64, 'top_p': 0.95}
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [serving_chat.py:134] Using default chat sampling params from model: {'top_k': 64, 'top_p': 0.95}
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [serving_completion.py:77] Using default completion sampling params from model: {'top_k': 64, 'top_p': 0.95}
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [api_server.py:1880] Starting vLLM API server 0 on http://0.0.0.0:8000
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:36] Available routes are:
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /openapi.json, Methods: HEAD, GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /docs, Methods: HEAD, GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /docs/oauth2-redirect, Methods: HEAD, GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /redoc, Methods: HEAD, GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /health, Methods: GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /load, Methods: GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /ping, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /ping, Methods: GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /tokenize, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /detokenize, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/models, Methods: GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /version, Methods: GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/responses, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/responses/{response_id}, Methods: GET
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/responses/{response_id}/cancel, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/chat/completions, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/completions, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/embeddings, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /pooling, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /classify, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /score, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/score, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/audio/transcriptions, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/audio/translations, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /rerank, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v1/rerank, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /v2/rerank, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /scale_elastic_ep, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /is_scaling_elastic_ep, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /invocations, Methods: POST
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:06 [launcher.py:44] Route: /metrics, Methods: GET
[1;36m(APIServer pid=296140)[0;0m INFO:     Started server process [296140]
[1;36m(APIServer pid=296140)[0;0m INFO:     Waiting for application startup.
[1;36m(APIServer pid=296140)[0;0m INFO:     Application startup complete.
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:55054 - "GET /health HTTP/1.1" 200 OK
[start_vllm_server] [37m✅ vLLM server is ready![0m
[start_vllm_server] 2025-09-17 03:25:08 | INFO     | benchy.vllm_server   | vLLM server started successfully
[37mStep [0m[38;5;105mstart_vllm_server[37m has finished in [0m[38;5;105m1m10s[37m.[0m
[37mStep [0m[38;5;105mtest_vllm_api[37m has started.[0m
[test_vllm_api] [37mTesting vLLM API at [0m[34mhttp://0.0.0.0:8000[37m[0m
[test_vllm_api] 2025-09-17 03:25:09 | INFO     | benchy.api_test      | === Testing vLLM API ===
[test_vllm_api] 2025-09-17 03:25:09 | INFO     | benchy.api_test      | Server URL: http://0.0.0.0:8000
[test_vllm_api] 2025-09-17 03:25:09 | INFO     | benchy.api_test      | Model: google/gemma-3n-E4B-it
[1;36m(EngineCore_0 pid=296654)[0;0m WARNING 09-17 03:25:09 [cudagraph_dispatcher.py:101] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:55062 - "POST /v1/completions HTTP/1.1" 200 OK
[test_vllm_api] [37m✅ API test successful![0m
[test_vllm_api] 2025-09-17 03:25:12 | INFO     | benchy.api_test      | API test completed successfully
[test_vllm_api] 2025-09-17 03:25:12 | INFO     | benchy.api_test      | Response: {'id': 'cmpl-1fb4330b94f4400c9c5c73f804d89fb0', 'object': 'text_completion', 'created': 1758079509, 'model': 'google/gemma-3n-E4B-it', 'choices': [{'index': 0, 'text': " I'm doing well, thank you!\n\nThat's great to hear! I'm doing well too, thanks for asking. \n\nIs there anything you'd like to talk about? I'm happy to chat about pretty much", 'logprobs': None, 'finish_reason': 'length', 'stop_reason': None, 'prompt_logprobs': None}], 'service_tier': None, 'system_fingerprint': None, 'usage': {'prompt_tokens': 7, 'total_tokens': 57, 'completion_tokens': 50, 'prompt_tokens_details': None}, 'kv_transfer_params': None}
[37mStep [0m[38;5;105mtest_vllm_api[37m has finished in [0m[38;5;105m2.890s[37m.[0m
[37mStep [0m[38;5;105mrun_portuguese_evaluation[37m has started.[0m
[run_portuguese_evaluation] [37mStarting Portuguese evaluation for model: google/gemma-3n-E4B-it, tasks: latam_pr[0m
[run_portuguese_evaluation] 2025-09-17 03:25:13 | INFO     | benchy.lm_eval       | === Starting Portuguese LM Evaluation ===
[run_portuguese_evaluation] 2025-09-17 03:25:13 | INFO     | benchy.lm_eval       | Model: google/gemma-3n-E4B-it
[run_portuguese_evaluation] 2025-09-17 03:25:13 | INFO     | benchy.lm_eval       | Tasks: latam_pr
[run_portuguese_evaluation] 2025-09-17 03:25:13 | INFO     | benchy.lm_eval       | Server URL: http://0.0.0.0:8000
[run_portuguese_evaluation] 2025-09-17 03:25:13 | INFO     | benchy.lm_eval       | Batch size: 10
[run_portuguese_evaluation] 2025-09-17 03:25:13 | INFO     | benchy.lm_eval       | Concurrent requests: 10
[run_portuguese_evaluation] 2025-09-17 03:25:13 | INFO     | benchy.lm_eval       | Limit: 10 (testing mode)
[run_portuguese_evaluation] [37mExecuting command: lm_eval --model local-completions --model_args model=google/gemma-3n-E4B-it,base_url=[0m[34mhttp://0.0.0.0:8000/v1/completions,num_concurrent=10,max_retries=3[37m --tasks latam_pr --batch_size 10 --output_path /home/mauro/dev/lm-evaluation-harness/output/portuguese --log_samples --limit 10 --wandb_args entity=surus-lat,project=LATAM-leaderboard --cache_requests true --trust_remote_code[0m
[run_portuguese_evaluation] 2025-09-17 03:25:13 | INFO     | benchy.lm_eval       | Full command: lm_eval --model local-completions --model_args model=google/gemma-3n-E4B-it,base_url=http://0.0.0.0:8000/v1/completions,num_concurrent=10,max_retries=3 --tasks latam_pr --batch_size 10 --output_path /home/mauro/dev/lm-evaluation-harness/output/portuguese --log_samples --limit 10 --wandb_args entity=surus-lat,project=LATAM-leaderboard --cache_requests true --trust_remote_code
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:16 [loggers.py:123] Engine 000: Avg prompt throughput: 0.6 tokens/s, Avg generation throughput: 4.5 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[run_portuguese_evaluation] [37m[lm_eval] INFO 09-17 03:25:19 [__init__.py:241] Automatically detected platform cuda.[0m
[run_portuguese_evaluation] 2025-09-17 03:25:19 | INFO     | benchy.lm_eval       | [lm_eval] INFO 09-17 03:25:19 [__init__.py:241] Automatically detected platform cuda.
[run_portuguese_evaluation] [37m[lm_eval] wandb: Currently logged in as: mauro-surus (surus-lat) to [0m[34mhttps://api.wandb.ai.[37m Use [0m[38;5;105mwandb login --relogin[37m to force relogin[0m
[run_portuguese_evaluation] 2025-09-17 03:25:22 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Currently logged in as: mauro-surus (surus-lat) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[run_portuguese_evaluation] [37m[lm_eval] wandb: creating run[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] wandb: creating run
[run_portuguese_evaluation] [37m[lm_eval] wandb: Tracking run with wandb version 0.21.3[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Tracking run with wandb version 0.21.3
[run_portuguese_evaluation] [37m[lm_eval] wandb: Run data is saved locally in /home/mauro/dev/lm-evaluation-harness/wandb/run-20250917_032522-5pbdefv9[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Run data is saved locally in /home/mauro/dev/lm-evaluation-harness/wandb/run-20250917_032522-5pbdefv9
[run_portuguese_evaluation] [37m[lm_eval] wandb: Run [0m[38;5;105mwandb offline[37m to turn off syncing.[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Run `wandb offline` to turn off syncing.
[run_portuguese_evaluation] [37m[lm_eval] wandb: Syncing run sweet-firebrand-90[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Syncing run sweet-firebrand-90
[run_portuguese_evaluation] [37m[lm_eval] wandb: ⭐️ View project at [0m[34mhttps://wandb.ai/surus-lat/LATAM-Leaderboard[37m[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] wandb: ⭐️ View project at https://wandb.ai/surus-lat/LATAM-Leaderboard
[run_portuguese_evaluation] [37m[lm_eval] wandb: 🚀 View run at [0m[34mhttps://wandb.ai/surus-lat/LATAM-Leaderboard/runs/5pbdefv9[37m[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] wandb: 🚀 View run at https://wandb.ai/surus-lat/LATAM-Leaderboard/runs/5pbdefv9
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:23 INFO     [tasks:476] The tag 'teleia' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:23 INFO     [tasks:476] The tag 'teleia' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:23 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:23 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:23 INFO     [__main__:429] Passed [0m[38;5;105m--trust_remote_code[37m, setting environment variable [0m[38;5;105mHF_DATASETS_TRUST_REMOTE_CODE=true[37m[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:23 INFO     [__main__:429] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:23 INFO     [__main__:446] Selected Tasks: ['latam_pr'][0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:23 INFO     [__main__:446] Selected Tasks: ['latam_pr']
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:23 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:23 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:23 INFO     [evaluator:240] Initializing local-completions model, with arguments: {'model': 'google/gemma-3n-E4B-it', 'base_url': '[0m[34mhttp://0.0.0.0:8000/v1/completions',[37m[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:23 INFO     [evaluator:240] Initializing local-completions model, with arguments: {'model': 'google/gemma-3n-E4B-it', 'base_url': 'http://0.0.0.0:8000/v1/completions',
[run_portuguese_evaluation] [37m[lm_eval]         'num_concurrent': 10, 'max_retries': 3, 'trust_remote_code': True}[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval]         'num_concurrent': 10, 'max_retries': 3, 'trust_remote_code': True}
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:23 WARNING  [models.api_models:162] Batch size > 1 detected. Ensure your API supports batched requests with varying total sequence lengths.[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:23 WARNING  [models.api_models:162] Batch size > 1 detected. Ensure your API supports batched requests with varying total sequence lengths.
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:23 INFO     [models.api_models:170] Using max length 2048 - 1[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:23 INFO     [models.api_models:170] Using max length 2048 - 1
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:23 INFO     [models.api_models:189] Using tokenizer huggingface[0m
[run_portuguese_evaluation] 2025-09-17 03:25:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:23 INFO     [models.api_models:189] Using tokenizer huggingface
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:26 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:29 INFO     [evaluator:574] Running loglikelihood requests[0m
[run_portuguese_evaluation] 2025-09-17 03:25:29 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:29 INFO     [evaluator:574] Running loglikelihood requests
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:39172 - "POST /v1/completions HTTP/1.1" 200 OK
[run_portuguese_evaluation] [37m[lm_eval] Requesting API:   0%|          | 0/4 [00:00<?, ?it/s][0m
[run_portuguese_evaluation] 2025-09-17 03:25:32 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:   0%|          | 0/4 [00:00<?, ?it/s]
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:39188 - "POST /v1/completions HTTP/1.1" 200 OK
[run_portuguese_evaluation] [37m[lm_eval] Requesting API:  25%|██▌       | 1/4 [00:02<00:06,  2.10s/it][0m
[run_portuguese_evaluation] 2025-09-17 03:25:33 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  25%|██▌       | 1/4 [00:02<00:06,  2.10s/it]
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:39192 - "POST /v1/completions HTTP/1.1" 200 OK
[run_portuguese_evaluation] [37m[lm_eval] Requesting API:  50%|█████     | 2/4 [00:03<00:02,  1.46s/it][0m
[run_portuguese_evaluation] 2025-09-17 03:25:34 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  50%|█████     | 2/4 [00:03<00:02,  1.46s/it]
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:39206 - "POST /v1/completions HTTP/1.1" 200 OK
[run_portuguese_evaluation] [37m[lm_eval] Requesting API:  75%|███████▌  | 3/4 [00:04<00:01,  1.25s/it][0m
[run_portuguese_evaluation] 2025-09-17 03:25:34 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  75%|███████▌  | 3/4 [00:04<00:01,  1.25s/it]
[run_portuguese_evaluation] [37m[lm_eval] Requesting API: 100%|██████████| 4/4 [00:04<00:00,  1.01it/s][0m
[run_portuguese_evaluation] 2025-09-17 03:25:34 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API: 100%|██████████| 4/4 [00:04<00:00,  1.01it/s]
[run_portuguese_evaluation] [37m[lm_eval] Requesting API: 100%|██████████| 4/4 [00:04<00:00,  1.17s/it][0m
[run_portuguese_evaluation] 2025-09-17 03:25:34 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API: 100%|██████████| 4/4 [00:04<00:00,  1.17s/it]
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:36 [loggers.py:123] Engine 000: Avg prompt throughput: 1617.2 tokens/s, Avg generation throughput: 4.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:40 INFO     [loggers.evaluation_tracker:209] Saving results aggregated[0m
[run_portuguese_evaluation] 2025-09-17 03:25:40 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:40 INFO     [loggers.evaluation_tracker:209] Saving results aggregated
[run_portuguese_evaluation] [37m[lm_eval] 2025-09-17:03:25:40 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: belebele_por_Latn[0m
[run_portuguese_evaluation] 2025-09-17 03:25:40 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:40 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: belebele_por_Latn
[run_portuguese_evaluation] [37m[lm_eval] wandb: uploading artifact results; uploading artifact run-5pbdefv9-belebele_por_Latn_eval_results; uploading artifact belebele_por_Latn; updating run metadata[0m
[run_portuguese_evaluation] 2025-09-17 03:25:40 | INFO     | benchy.lm_eval       | [lm_eval] wandb: uploading artifact results; uploading artifact run-5pbdefv9-belebele_por_Latn_eval_results; uploading artifact belebele_por_Latn; updating run metadata
[run_portuguese_evaluation] [37m[lm_eval] wandb: uploading artifact run-5pbdefv9-belebele_por_Latn_eval_results; uploading artifact belebele_por_Latn; uploading config.yaml[0m
[run_portuguese_evaluation] 2025-09-17 03:25:41 | INFO     | benchy.lm_eval       | [lm_eval] wandb: uploading artifact run-5pbdefv9-belebele_por_Latn_eval_results; uploading artifact belebele_por_Latn; uploading config.yaml
[run_portuguese_evaluation] [37m[lm_eval] wandb: uploading artifact belebele_por_Latn[0m
[run_portuguese_evaluation] 2025-09-17 03:25:42 | INFO     | benchy.lm_eval       | [lm_eval] wandb: uploading artifact belebele_por_Latn
[run_portuguese_evaluation] [37m[lm_eval] wandb:[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:
[run_portuguese_evaluation] [37m[lm_eval] wandb:[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:
[run_portuguese_evaluation] [37m[lm_eval] wandb: Run history:[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Run history:
[run_portuguese_evaluation] [37m[lm_eval] wandb:             belebele_por_Latn/acc ▁[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:             belebele_por_Latn/acc ▁
[run_portuguese_evaluation] [37m[lm_eval] wandb:        belebele_por_Latn/acc_norm ▁[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:        belebele_por_Latn/acc_norm ▁
[run_portuguese_evaluation] [37m[lm_eval] wandb: belebele_por_Latn/acc_norm_stderr ▁[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb: belebele_por_Latn/acc_norm_stderr ▁
[run_portuguese_evaluation] [37m[lm_eval] wandb:      belebele_por_Latn/acc_stderr ▁[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:      belebele_por_Latn/acc_stderr ▁
[run_portuguese_evaluation] [37m[lm_eval] wandb:                      latam_pr/acc ▁[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                      latam_pr/acc ▁
[run_portuguese_evaluation] [37m[lm_eval] wandb:               latam_pr/acc_stderr ▁[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:               latam_pr/acc_stderr ▁
[run_portuguese_evaluation] [37m[lm_eval] wandb:                    portuguese/acc ▁[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                    portuguese/acc ▁
[run_portuguese_evaluation] [37m[lm_eval] wandb:             portuguese/acc_stderr ▁[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:             portuguese/acc_stderr ▁
[run_portuguese_evaluation] [37m[lm_eval] wandb:[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:
[run_portuguese_evaluation] [37m[lm_eval] wandb: Run summary:[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Run summary:
[run_portuguese_evaluation] [37m[lm_eval] wandb:             belebele_por_Latn/acc 0.9[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:             belebele_por_Latn/acc 0.9
[run_portuguese_evaluation] [37m[lm_eval] wandb:        belebele_por_Latn/acc_norm 0.9[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:        belebele_por_Latn/acc_norm 0.9
[run_portuguese_evaluation] [37m[lm_eval] wandb: belebele_por_Latn/acc_norm_stderr 0.1[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb: belebele_por_Latn/acc_norm_stderr 0.1
[run_portuguese_evaluation] [37m[lm_eval] wandb:      belebele_por_Latn/acc_stderr 0.1[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:      belebele_por_Latn/acc_stderr 0.1
[run_portuguese_evaluation] [37m[lm_eval] wandb:           belebele_por_Latn/alias   - belebele_por_Lat...[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:           belebele_por_Latn/alias   - belebele_por_Lat...
[run_portuguese_evaluation] [37m[lm_eval] wandb:                      latam_pr/acc 0.9[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                      latam_pr/acc 0.9
[run_portuguese_evaluation] [37m[lm_eval] wandb:               latam_pr/acc_stderr 0.1[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:               latam_pr/acc_stderr 0.1
[run_portuguese_evaluation] [37m[lm_eval] wandb:                    latam_pr/alias latam_pr[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                    latam_pr/alias latam_pr
[run_portuguese_evaluation] [37m[lm_eval] wandb:                    portuguese/acc 0.9[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                    portuguese/acc 0.9
[run_portuguese_evaluation] [37m[lm_eval] wandb:             portuguese/acc_stderr 0.1[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:             portuguese/acc_stderr 0.1
[run_portuguese_evaluation] [37m[lm_eval] wandb:                                +1 ...[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                                +1 ...
[run_portuguese_evaluation] [37m[lm_eval] wandb:[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb:
[run_portuguese_evaluation] [37m[lm_eval] wandb: 🚀 View run sweet-firebrand-90 at: [0m[34mhttps://wandb.ai/surus-lat/LATAM-Leaderboard/runs/5pbdefv9[37m[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb: 🚀 View run sweet-firebrand-90 at: https://wandb.ai/surus-lat/LATAM-Leaderboard/runs/5pbdefv9
[run_portuguese_evaluation] [37m[lm_eval] wandb: ⭐️ View project at: [0m[34mhttps://wandb.ai/surus-lat/LATAM-Leaderboard[37m[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb: ⭐️ View project at: https://wandb.ai/surus-lat/LATAM-Leaderboard
[run_portuguese_evaluation] [37m[lm_eval] wandb: Synced 5 W&B file(s), 3 media file(s), 10 artifact file(s) and 0 other file(s)[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Synced 5 W&B file(s), 3 media file(s), 10 artifact file(s) and 0 other file(s)
[run_portuguese_evaluation] [37m[lm_eval] wandb: Find logs at: ./wandb/run-20250917_032522-5pbdefv9/logs[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Find logs at: ./wandb/run-20250917_032522-5pbdefv9/logs
[run_portuguese_evaluation] [37m[lm_eval] local-completions (model=google/gemma-3n-E4B-it,base_url=[0m[34mhttp://0.0.0.0:8000/v1/completions,num_concurrent=10,max_retries=3,trust_remote_code=True),[37m gen_kwargs: (None), limit: 10.0, num_fewshot: None, batch_size: 10[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] local-completions (model=google/gemma-3n-E4B-it,base_url=http://0.0.0.0:8000/v1/completions,num_concurrent=10,max_retries=3,trust_remote_code=True), gen_kwargs: (None), limit: 10.0, num_fewshot: None, batch_size: 10
[run_portuguese_evaluation] [37m[lm_eval] |        Tasks        |Version|Filter|n-shot| Metric |   |Value|   |Stderr|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] |        Tasks        |Version|Filter|n-shot| Metric |   |Value|   |Stderr|
[run_portuguese_evaluation] [37m[lm_eval] |---------------------|------:|------|-----:|--------|---|----:|---|-----:|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] |---------------------|------:|------|-----:|--------|---|----:|---|-----:|
[run_portuguese_evaluation] [37m[lm_eval] |latam_pr             |      1|none  |      |acc     |↑  |  0.9|±  |   0.1|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] |latam_pr             |      1|none  |      |acc     |↑  |  0.9|±  |   0.1|
[run_portuguese_evaluation] [37m[lm_eval] | - portuguese        |      1|none  |      |acc     |↑  |  0.9|±  |   0.1|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] | - portuguese        |      1|none  |      |acc     |↑  |  0.9|±  |   0.1|
[run_portuguese_evaluation] [37m[lm_eval] |  - belebele_por_Latn|      0|none  |     1|acc     |↑  |  0.9|±  |   0.1|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] |  - belebele_por_Latn|      0|none  |     1|acc     |↑  |  0.9|±  |   0.1|
[run_portuguese_evaluation] [37m[lm_eval] |                     |       |none  |     1|acc_norm|↑  |  0.9|±  |   0.1|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] |                     |       |none  |     1|acc_norm|↑  |  0.9|±  |   0.1|
[run_portuguese_evaluation] [37m[lm_eval] |   Groups    |Version|Filter|n-shot|Metric|   |Value|   |Stderr|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] |   Groups    |Version|Filter|n-shot|Metric|   |Value|   |Stderr|
[run_portuguese_evaluation] [37m[lm_eval] |-------------|------:|------|------|------|---|----:|---|-----:|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] |-------------|------:|------|------|------|---|----:|---|-----:|
[run_portuguese_evaluation] [37m[lm_eval] |latam_pr     |      1|none  |      |acc   |↑  |  0.9|±  |   0.1|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] |latam_pr     |      1|none  |      |acc   |↑  |  0.9|±  |   0.1|
[run_portuguese_evaluation] [37m[lm_eval] | - portuguese|      1|none  |      |acc   |↑  |  0.9|±  |   0.1|[0m
[run_portuguese_evaluation] 2025-09-17 03:25:43 | INFO     | benchy.lm_eval       | [lm_eval] | - portuguese|      1|none  |      |acc   |↑  |  0.9|±  |   0.1|
[run_portuguese_evaluation] [37mlm_eval completed successfully[0m
[run_portuguese_evaluation] 2025-09-17 03:25:45 | INFO     | benchy.lm_eval       | === LM Evaluation COMPLETED SUCCESSFULLY ===
[run_portuguese_evaluation] 2025-09-17 03:25:45 | INFO     | benchy.lm_eval       | Output saved to: /home/mauro/dev/lm-evaluation-harness/output/portuguese
[37mStep [0m[38;5;105mrun_portuguese_evaluation[37m has finished in [0m[38;5;105m32.188s[37m.[0m
[37mStep [0m[38;5;105mrun_spanish_evaluation[37m has started.[0m
[run_spanish_evaluation] [37mStarting Spanish evaluation for model: google/gemma-3n-E4B-it, tasks: latam_es[0m
[run_spanish_evaluation] 2025-09-17 03:25:46 | INFO     | benchy.lm_eval       | === Starting Spanish LM Evaluation ===
[run_spanish_evaluation] 2025-09-17 03:25:46 | INFO     | benchy.lm_eval       | Model: google/gemma-3n-E4B-it
[run_spanish_evaluation] 2025-09-17 03:25:46 | INFO     | benchy.lm_eval       | Tasks: latam_es
[run_spanish_evaluation] 2025-09-17 03:25:46 | INFO     | benchy.lm_eval       | Server URL: http://0.0.0.0:8000
[run_spanish_evaluation] 2025-09-17 03:25:46 | INFO     | benchy.lm_eval       | Batch size: 10
[run_spanish_evaluation] 2025-09-17 03:25:46 | INFO     | benchy.lm_eval       | Concurrent requests: 10
[run_spanish_evaluation] 2025-09-17 03:25:46 | INFO     | benchy.lm_eval       | Limit: 10 (testing mode)
[run_spanish_evaluation] [37mExecuting command: lm_eval --model local-completions --model_args model=google/gemma-3n-E4B-it,base_url=[0m[34mhttp://0.0.0.0:8000/v1/completions,num_concurrent=10,max_retries=3[37m --tasks latam_es --batch_size 10 --output_path /home/mauro/dev/lm-evaluation-harness/output/spanish --log_samples --limit 10 --wandb_args entity=surus-lat,project=LATAM-leaderboard --cache_requests true --trust_remote_code[0m
[run_spanish_evaluation] 2025-09-17 03:25:46 | INFO     | benchy.lm_eval       | Full command: lm_eval --model local-completions --model_args model=google/gemma-3n-E4B-it,base_url=http://0.0.0.0:8000/v1/completions,num_concurrent=10,max_retries=3 --tasks latam_es --batch_size 10 --output_path /home/mauro/dev/lm-evaluation-harness/output/spanish --log_samples --limit 10 --wandb_args entity=surus-lat,project=LATAM-leaderboard --cache_requests true --trust_remote_code
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:25:46 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.0%, Prefix cache hit rate: 0.0%
[run_spanish_evaluation] [37m[lm_eval] INFO 09-17 03:25:52 [__init__.py:241] Automatically detected platform cuda.[0m
[run_spanish_evaluation] 2025-09-17 03:25:52 | INFO     | benchy.lm_eval       | [lm_eval] INFO 09-17 03:25:52 [__init__.py:241] Automatically detected platform cuda.
[run_spanish_evaluation] [37m[lm_eval] wandb: Currently logged in as: mauro-surus (surus-lat) to [0m[34mhttps://api.wandb.ai.[37m Use [0m[38;5;105mwandb login --relogin[37m to force relogin[0m
[run_spanish_evaluation] 2025-09-17 03:25:55 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Currently logged in as: mauro-surus (surus-lat) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
[run_spanish_evaluation] [37m[lm_eval] wandb: creating run[0m
[run_spanish_evaluation] 2025-09-17 03:25:56 | INFO     | benchy.lm_eval       | [lm_eval] wandb: creating run
[run_spanish_evaluation] [37m[lm_eval] wandb: Tracking run with wandb version 0.21.3[0m
[run_spanish_evaluation] 2025-09-17 03:25:56 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Tracking run with wandb version 0.21.3
[run_spanish_evaluation] [37m[lm_eval] wandb: Run data is saved locally in /home/mauro/dev/lm-evaluation-harness/wandb/run-20250917_032555-87k5sl7t[0m
[run_spanish_evaluation] 2025-09-17 03:25:56 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Run data is saved locally in /home/mauro/dev/lm-evaluation-harness/wandb/run-20250917_032555-87k5sl7t
[run_spanish_evaluation] [37m[lm_eval] wandb: Run [0m[38;5;105mwandb offline[37m to turn off syncing.[0m
[run_spanish_evaluation] 2025-09-17 03:25:56 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Run `wandb offline` to turn off syncing.
[run_spanish_evaluation] [37m[lm_eval] wandb: Syncing run vibrant-breeze-91[0m
[run_spanish_evaluation] 2025-09-17 03:25:56 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Syncing run vibrant-breeze-91
[run_spanish_evaluation] [37m[lm_eval] wandb: ⭐️ View project at [0m[34mhttps://wandb.ai/surus-lat/LATAM-Leaderboard[37m[0m
[run_spanish_evaluation] 2025-09-17 03:25:56 | INFO     | benchy.lm_eval       | [lm_eval] wandb: ⭐️ View project at https://wandb.ai/surus-lat/LATAM-Leaderboard
[run_spanish_evaluation] [37m[lm_eval] wandb: 🚀 View run at [0m[34mhttps://wandb.ai/surus-lat/LATAM-Leaderboard/runs/87k5sl7t[37m[0m
[run_spanish_evaluation] 2025-09-17 03:25:56 | INFO     | benchy.lm_eval       | [lm_eval] wandb: 🚀 View run at https://wandb.ai/surus-lat/LATAM-Leaderboard/runs/87k5sl7t
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:25:57 INFO     [tasks:476] The tag 'teleia' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.[0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:57 INFO     [tasks:476] The tag 'teleia' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:25:57 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.[0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:57 WARNING  [__main__:369]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:25:57 INFO     [__main__:429] Passed [0m[38;5;105m--trust_remote_code[37m, setting environment variable [0m[38;5;105mHF_DATASETS_TRUST_REMOTE_CODE=true[37m[0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:57 INFO     [__main__:429] Passed `--trust_remote_code`, setting environment variable `HF_DATASETS_TRUST_REMOTE_CODE=true`
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:25:57 INFO     [__main__:446] Selected Tasks: ['latam_es'][0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:57 INFO     [__main__:446] Selected Tasks: ['latam_es']
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:25:57 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234[0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:57 INFO     [evaluator:202] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:25:57 INFO     [evaluator:240] Initializing local-completions model, with arguments: {'model': 'google/gemma-3n-E4B-it', 'base_url': '[0m[34mhttp://0.0.0.0:8000/v1/completions',[37m[0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:57 INFO     [evaluator:240] Initializing local-completions model, with arguments: {'model': 'google/gemma-3n-E4B-it', 'base_url': 'http://0.0.0.0:8000/v1/completions',
[run_spanish_evaluation] [37m[lm_eval]         'num_concurrent': 10, 'max_retries': 3, 'trust_remote_code': True}[0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval]         'num_concurrent': 10, 'max_retries': 3, 'trust_remote_code': True}
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:25:57 WARNING  [models.api_models:162] Batch size > 1 detected. Ensure your API supports batched requests with varying total sequence lengths.[0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:57 WARNING  [models.api_models:162] Batch size > 1 detected. Ensure your API supports batched requests with varying total sequence lengths.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:25:57 INFO     [models.api_models:170] Using max length 2048 - 1[0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:57 INFO     [models.api_models:170] Using max length 2048 - 1
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:25:57 INFO     [models.api_models:189] Using tokenizer huggingface[0m
[run_spanish_evaluation] 2025-09-17 03:25:57 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:25:57 INFO     [models.api_models:189] Using tokenizer huggingface
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:05 WARNING  [api.task:1062] [Task: xnli_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:05 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:05 WARNING  [api.task:1062] [Task: xnli_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:05 WARNING  [api.task:1062] [Task: xnli_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:05 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:05 WARNING  [api.task:1062] [Task: xnli_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] /home/mauro/dev/lm-evaluation-harness/.venv/lib/python3.12/site-packages/datasets/load.py:1231: FutureWarning: The repository for PlanTL-GOB-ES/wnli-es contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at [0m[34mhttps://hf.co/datasets/PlanTL-GOB-ES/wnli-es[37m[0m
[run_spanish_evaluation] 2025-09-17 03:26:06 | INFO     | benchy.lm_eval       | [lm_eval] /home/mauro/dev/lm-evaluation-harness/.venv/lib/python3.12/site-packages/datasets/load.py:1231: FutureWarning: The repository for PlanTL-GOB-ES/wnli-es contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/PlanTL-GOB-ES/wnli-es
[run_spanish_evaluation] [37m[lm_eval] You can avoid this message in future by passing the argument [0m[38;5;105mtrust_remote_code=True[37m.[0m
[run_spanish_evaluation] 2025-09-17 03:26:06 | INFO     | benchy.lm_eval       | [lm_eval] You can avoid this message in future by passing the argument `trust_remote_code=True`.
[run_spanish_evaluation] [37m[lm_eval] Passing [0m[38;5;105mtrust_remote_code=True[37m will be mandatory to load this dataset from the next major release of [0m[38;5;105mdatasets[37m.[0m
[run_spanish_evaluation] 2025-09-17 03:26:06 | INFO     | benchy.lm_eval       | [lm_eval] Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
[run_spanish_evaluation] [37m[lm_eval]   warnings.warn([0m
[run_spanish_evaluation] 2025-09-17 03:26:06 | INFO     | benchy.lm_eval       | [lm_eval]   warnings.warn(
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:07 WARNING  [api.task:1062] [Task: wnli_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:07 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:07 WARNING  [api.task:1062] [Task: wnli_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:07 WARNING  [api.task:1062] [Task: wnli_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:07 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:07 WARNING  [api.task:1062] [Task: wnli_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:09 WARNING  [api.task:1062] [Task: teleia_siele] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:09 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:09 WARNING  [api.task:1062] [Task: teleia_siele] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:09 WARNING  [api.task:1062] [Task: teleia_siele] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:09 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:09 WARNING  [api.task:1062] [Task: teleia_siele] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:10 WARNING  [api.task:1062] [Task: teleia_cervantes_ave] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:10 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:10 WARNING  [api.task:1062] [Task: teleia_cervantes_ave] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:10 WARNING  [api.task:1062] [Task: teleia_cervantes_ave] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:10 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:10 WARNING  [api.task:1062] [Task: teleia_cervantes_ave] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:13 WARNING  [api.task:1062] [Task: teleia_pce] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:13 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:13 WARNING  [api.task:1062] [Task: teleia_pce] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:13 WARNING  [api.task:1062] [Task: teleia_pce] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:13 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:13 WARNING  [api.task:1062] [Task: teleia_pce] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:18 WARNING  [api.task:1062] [Task: paws_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:18 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:18 WARNING  [api.task:1062] [Task: paws_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:18 WARNING  [api.task:1062] [Task: paws_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:18 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:18 WARNING  [api.task:1062] [Task: paws_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:23 WARNING  [api.task:1062] [Task: openbookqa_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:23 WARNING  [api.task:1062] [Task: openbookqa_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:23 WARNING  [api.task:1062] [Task: openbookqa_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:23 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:23 WARNING  [api.task:1062] [Task: openbookqa_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:25 WARNING  [api.task:1062] [Task: mgsm_direct_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:25 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:25 WARNING  [api.task:1062] [Task: mgsm_direct_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:25 WARNING  [api.task:1062] [Task: mgsm_direct_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:25 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:25 WARNING  [api.task:1062] [Task: mgsm_direct_es_spanish_bench] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:27 WARNING  [api.task:1062] [Task: escola] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:27 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:27 WARNING  [api.task:1062] [Task: escola] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:27 WARNING  [api.task:1062] [Task: escola] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:27 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:27 WARNING  [api.task:1062] [Task: escola] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:30 WARNING  [api.task:1062] [Task: copa_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:30 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:30 WARNING  [api.task:1062] [Task: copa_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:30 WARNING  [api.task:1062] [Task: copa_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.[0m
[run_spanish_evaluation] 2025-09-17 03:26:30 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:30 WARNING  [api.task:1062] [Task: copa_es] num_fewshot > 0 but fewshot_split is None. using preconfigured rule.
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:31 INFO     [evaluator:305] mgsm_direct_es_spanish_bench: Using gen_kwargs: {'do_sample': False, 'until': ['\n\n', '\n', 'Pregunta:', '</s>', '<|im_end|>']}[0m
[run_spanish_evaluation] 2025-09-17 03:26:31 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:31 INFO     [evaluator:305] mgsm_direct_es_spanish_bench: Using gen_kwargs: {'do_sample': False, 'until': ['\n\n', '\n', 'Pregunta:', '</s>', '<|im_end|>']}
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:31 INFO     [evaluator:574] Running loglikelihood requests[0m
[run_spanish_evaluation] 2025-09-17 03:26:31 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:31 INFO     [evaluator:574] Running loglikelihood requests
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52510 - "POST /v1/completions HTTP/1.1" 200 OK
[run_spanish_evaluation] [37m[lm_eval] Requesting API:   0%|          | 0/22 [00:00<?, ?it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:34 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:   0%|          | 0/22 [00:00<?, ?it/s]
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52518 - "POST /v1/completions HTTP/1.1" 200 OK
[run_spanish_evaluation] [37m[lm_eval] Requesting API:   5%|▍         | 1/22 [00:03<01:11,  3.40s/it][0m
[run_spanish_evaluation] 2025-09-17 03:26:36 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:   5%|▍         | 1/22 [00:03<01:11,  3.40s/it]
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52520 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52536 - "POST /v1/completions HTTP/1.1" 200 OK
[run_spanish_evaluation] [37m[lm_eval] Requesting API:   9%|▉         | 2/22 [00:04<00:44,  2.25s/it][0m
[run_spanish_evaluation] 2025-09-17 03:26:36 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:   9%|▉         | 2/22 [00:04<00:44,  2.25s/it]
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:26:36 [loggers.py:123] Engine 000: Avg prompt throughput: 2040.4 tokens/s, Avg generation throughput: 4.0 tokens/s, Running: 1 reqs, Waiting: 69 reqs, GPU KV cache usage: 0.1%, Prefix cache hit rate: 0.0%
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52542 - "POST /v1/completions HTTP/1.1" 200 OK
[run_spanish_evaluation] [37m[lm_eval] Requesting API:  14%|█▎        | 3/22 [00:05<00:27,  1.44s/it][0m
[run_spanish_evaluation] 2025-09-17 03:26:37 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  14%|█▎        | 3/22 [00:05<00:27,  1.44s/it]
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52556 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52564 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52572 - "POST /v1/completions HTTP/1.1" 200 OK
[run_spanish_evaluation] [37m[lm_eval] Requesting API:  23%|██▎       | 5/22 [00:05<00:13,  1.31it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:37 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  23%|██▎       | 5/22 [00:05<00:13,  1.31it/s]
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52576 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52592 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52510 - "POST /v1/completions HTTP/1.1" 200 OK
[run_spanish_evaluation] [37m[lm_eval] Requesting API:  27%|██▋       | 6/22 [00:06<00:11,  1.42it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:38 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  27%|██▋       | 6/22 [00:06<00:11,  1.42it/s]
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52518 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52536 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52520 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52542 - "POST /v1/completions HTTP/1.1" 200 OK
[run_spanish_evaluation] [37m[lm_eval] Requesting API:  41%|████      | 9/22 [00:06<00:05,  2.40it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:38 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  41%|████      | 9/22 [00:06<00:05,  2.40it/s]
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52556 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52564 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52572 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52576 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52592 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52510 - "POST /v1/completions HTTP/1.1" 200 OK
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:52518 - "POST /v1/completions HTTP/1.1" 200 OK
[run_spanish_evaluation] [37m[lm_eval] Requesting API:  55%|█████▍    | 12/22 [00:07<00:03,  3.18it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:39 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  55%|█████▍    | 12/22 [00:07<00:03,  3.18it/s]
[run_spanish_evaluation] [37m[lm_eval] Requesting API:  73%|███████▎  | 16/22 [00:08<00:01,  4.20it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:39 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:  73%|███████▎  | 16/22 [00:08<00:01,  4.20it/s]
[run_spanish_evaluation] [37m[lm_eval] Requesting API: 100%|██████████| 22/22 [00:08<00:00,  2.73it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:39 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API: 100%|██████████| 22/22 [00:08<00:00,  2.73it/s]
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:26:39 INFO     [evaluator:574] Running generate_until requests[0m
[run_spanish_evaluation] 2025-09-17 03:26:39 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:26:39 INFO     [evaluator:574] Running generate_until requests
[1;36m(APIServer pid=296140)[0;0m INFO:     127.0.0.1:57174 - "POST /v1/completions HTTP/1.1" 200 OK
[run_spanish_evaluation] [37m[lm_eval] Requesting API:   0%|          | 0/1 [00:00<?, ?it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:39 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API:   0%|          | 0/1 [00:00<?, ?it/s]
[run_spanish_evaluation] [37m[lm_eval] Requesting API: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:39 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]
[run_spanish_evaluation] [37m[lm_eval] Requesting API: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s][0m
[run_spanish_evaluation] 2025-09-17 03:26:39 | INFO     | benchy.lm_eval       | [lm_eval] Requesting API: 100%|██████████| 1/1 [00:00<00:00,  2.20it/s]
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:26:46 [loggers.py:123] Engine 000: Avg prompt throughput: 1163.7 tokens/s, Avg generation throughput: 20.9 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.2%, Prefix cache hit rate: 19.9%
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:26:56 [loggers.py:123] Engine 000: Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 1 reqs, Waiting: 0 reqs, GPU KV cache usage: 0.2%, Prefix cache hit rate: 19.9%
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:209] Saving results aggregated[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:209] Saving results aggregated
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: copa_es[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: copa_es
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: escola[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: escola
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: mgsm_direct_es_spanish_bench[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: mgsm_direct_es_spanish_bench
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: openbookqa_es[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: openbookqa_es
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: paws_es_spanish_bench[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: paws_es_spanish_bench
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: teleia_cervantes_ave[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: teleia_cervantes_ave
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: teleia_pce[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: teleia_pce
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: teleia_siele[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: teleia_siele
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: wnli_es[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: wnli_es
[run_spanish_evaluation] [37m[lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: xnli_es_spanish_bench[0m
[run_spanish_evaluation] 2025-09-17 03:27:04 | INFO     | benchy.lm_eval       | [lm_eval] 2025-09-17:03:27:04 INFO     [loggers.evaluation_tracker:298] Saving per-sample results for: xnli_es_spanish_bench
[run_spanish_evaluation] [37m[lm_eval] wandb: uploading artifact run-87k5sl7t-xnli_es_spanish_bench_eval_results; updating run metadata[0m
[run_spanish_evaluation] 2025-09-17 03:27:05 | INFO     | benchy.lm_eval       | [lm_eval] wandb: uploading artifact run-87k5sl7t-xnli_es_spanish_bench_eval_results; updating run metadata
[run_spanish_evaluation] [37m[lm_eval] wandb: uploading config.yaml[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb: uploading config.yaml
[run_spanish_evaluation] [37m[lm_eval] wandb:[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:
[run_spanish_evaluation] [37m[lm_eval] wandb:[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:
[run_spanish_evaluation] [37m[lm_eval] wandb: Run history:[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Run history:
[run_spanish_evaluation] [37m[lm_eval] wandb:                                     copa_es/acc ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                                     copa_es/acc ▁
[run_spanish_evaluation] [37m[lm_eval] wandb:                              copa_es/acc_stderr ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                              copa_es/acc_stderr ▁
[run_spanish_evaluation] [37m[lm_eval] wandb:                                      escola/acc ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                                      escola/acc ▁
[run_spanish_evaluation] [37m[lm_eval] wandb:                               escola/acc_stderr ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                               escola/acc_stderr ▁
[run_spanish_evaluation] [37m[lm_eval] wandb:                                    latam_es/acc ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                                    latam_es/acc ▁
[run_spanish_evaluation] [37m[lm_eval] wandb:                             latam_es/acc_stderr ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                             latam_es/acc_stderr ▁
[run_spanish_evaluation] [37m[lm_eval] wandb:        mgsm_direct_es_spanish_bench/exact_match ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:        mgsm_direct_es_spanish_bench/exact_match ▁
[run_spanish_evaluation] [37m[lm_eval] wandb: mgsm_direct_es_spanish_bench/exact_match_stderr ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb: mgsm_direct_es_spanish_bench/exact_match_stderr ▁
[run_spanish_evaluation] [37m[lm_eval] wandb:                               openbookqa_es/acc ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                               openbookqa_es/acc ▁
[run_spanish_evaluation] [37m[lm_eval] wandb:                          openbookqa_es/acc_norm ▁[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                          openbookqa_es/acc_norm ▁
[run_spanish_evaluation] [37m[lm_eval] wandb:                                             +26 ...[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                                             +26 ...
[run_spanish_evaluation] [37m[lm_eval] wandb:[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:
[run_spanish_evaluation] [37m[lm_eval] wandb: Run summary:[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Run summary:
[run_spanish_evaluation] [37m[lm_eval] wandb:                        copa_es/acc 0.5[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                        copa_es/acc 0.5
[run_spanish_evaluation] [37m[lm_eval] wandb:                 copa_es/acc_stderr 0.16667[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                 copa_es/acc_stderr 0.16667
[run_spanish_evaluation] [37m[lm_eval] wandb:                      copa_es/alias   - copa_es[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                      copa_es/alias   - copa_es
[run_spanish_evaluation] [37m[lm_eval] wandb:                         escola/acc 0.4[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                         escola/acc 0.4
[run_spanish_evaluation] [37m[lm_eval] wandb:                  escola/acc_stderr 0.1633[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                  escola/acc_stderr 0.1633
[run_spanish_evaluation] [37m[lm_eval] wandb:                       escola/alias   - escola[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                       escola/alias   - escola
[run_spanish_evaluation] [37m[lm_eval] wandb:                       latam_es/acc 0.45119[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                       latam_es/acc 0.45119
[run_spanish_evaluation] [37m[lm_eval] wandb:                latam_es/acc_stderr 0.05106[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                latam_es/acc_stderr 0.05106
[run_spanish_evaluation] [37m[lm_eval] wandb:                     latam_es/alias latam_es[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                     latam_es/alias latam_es
[run_spanish_evaluation] [37m[lm_eval] wandb: mgsm_direct_es_spanish_bench/alias   - mgsm_direct_es_s...[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb: mgsm_direct_es_spanish_bench/alias   - mgsm_direct_es_s...
[run_spanish_evaluation] [37m[lm_eval] wandb:                                +39 ...[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:                                +39 ...
[run_spanish_evaluation] [37m[lm_eval] wandb:[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb:
[run_spanish_evaluation] [37m[lm_eval] wandb: 🚀 View run vibrant-breeze-91 at: [0m[34mhttps://wandb.ai/surus-lat/LATAM-Leaderboard/runs/87k5sl7t[37m[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb: 🚀 View run vibrant-breeze-91 at: https://wandb.ai/surus-lat/LATAM-Leaderboard/runs/87k5sl7t
[run_spanish_evaluation] [37m[lm_eval] wandb: ⭐️ View project at: [0m[34mhttps://wandb.ai/surus-lat/LATAM-Leaderboard[37m[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb: ⭐️ View project at: https://wandb.ai/surus-lat/LATAM-Leaderboard
[run_spanish_evaluation] [37m[lm_eval] wandb: Synced 5 W&B file(s), 12 media file(s), 26 artifact file(s) and 0 other file(s)[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Synced 5 W&B file(s), 12 media file(s), 26 artifact file(s) and 0 other file(s)
[run_spanish_evaluation] [37m[lm_eval] wandb: Find logs at: ./wandb/run-20250917_032555-87k5sl7t/logs[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] wandb: Find logs at: ./wandb/run-20250917_032555-87k5sl7t/logs
[run_spanish_evaluation] [37m[lm_eval] local-completions (model=google/gemma-3n-E4B-it,base_url=[0m[34mhttp://0.0.0.0:8000/v1/completions,num_concurrent=10,max_retries=3,trust_remote_code=True),[37m gen_kwargs: (None), limit: 10.0, num_fewshot: None, batch_size: 10[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] local-completions (model=google/gemma-3n-E4B-it,base_url=http://0.0.0.0:8000/v1/completions,num_concurrent=10,max_retries=3,trust_remote_code=True), gen_kwargs: (None), limit: 10.0, num_fewshot: None, batch_size: 10
[run_spanish_evaluation] [37m[lm_eval] |             Tasks              |Version|Filter|n-shot|  Metric   |   |Value |   |Stderr|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |             Tasks              |Version|Filter|n-shot|  Metric   |   |Value |   |Stderr|
[run_spanish_evaluation] [37m[lm_eval] |--------------------------------|------:|------|-----:|-----------|---|-----:|---|-----:|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |--------------------------------|------:|------|-----:|-----------|---|-----:|---|-----:|
[run_spanish_evaluation] [37m[lm_eval] |latam_es                        |      1|none  |      |acc        |↑  |0.4512|±  |0.0511|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |latam_es                        |      1|none  |      |acc        |↑  |0.4512|±  |0.0511|
[run_spanish_evaluation] [37m[lm_eval] | - spanish                      |      1|none  |      |acc        |↑  |0.4691|±  |0.0511|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] | - spanish                      |      1|none  |      |acc        |↑  |0.4691|±  |0.0511|
[run_spanish_evaluation] [37m[lm_eval] |  - copa_es                     |      1|none  |     1|acc        |↑  |0.5000|±  |0.1667|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  - copa_es                     |      1|none  |     1|acc        |↑  |0.5000|±  |0.1667|
[run_spanish_evaluation] [37m[lm_eval] |  - escola                      |      1|none  |     1|acc        |↑  |0.4000|±  |0.1633|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  - escola                      |      1|none  |     1|acc        |↑  |0.4000|±  |0.1633|
[run_spanish_evaluation] [37m[lm_eval] |  - mgsm_direct_es_spanish_bench|      1|none  |     1|exact_match|↑  |0.0000|±  |0.0000|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  - mgsm_direct_es_spanish_bench|      1|none  |     1|exact_match|↑  |0.0000|±  |0.0000|
[run_spanish_evaluation] [37m[lm_eval] |  - openbookqa_es               |      1|none  |     1|acc        |↑  |0.2000|±  |0.1333|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  - openbookqa_es               |      1|none  |     1|acc        |↑  |0.2000|±  |0.1333|
[run_spanish_evaluation] [37m[lm_eval] |                                |       |none  |     1|acc_norm   |↑  |0.2000|±  |0.1333|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |                                |       |none  |     1|acc_norm   |↑  |0.2000|±  |0.1333|
[run_spanish_evaluation] [37m[lm_eval] |  - paws_es_spanish_bench       |      1|none  |     1|acc        |↑  |0.6000|±  |0.1633|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  - paws_es_spanish_bench       |      1|none  |     1|acc        |↑  |0.6000|±  |0.1633|
[run_spanish_evaluation] [37m[lm_eval] |  - teleia                      |      1|none  |      |acc        |↑  |0.4286|±  |0.0781|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  - teleia                      |      1|none  |      |acc        |↑  |0.4286|±  |0.0781|
[run_spanish_evaluation] [37m[lm_eval] |                                |       |none  |      |acc_norm   |↑  |0.4286|±  |0.0998|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |                                |       |none  |      |acc_norm   |↑  |0.4286|±  |0.0998|
[run_spanish_evaluation] [37m[lm_eval] |   - teleia_cervantes_ave       |      1|none  |     1|acc        |↑  |0.0000|±  |0.0000|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |   - teleia_cervantes_ave       |      1|none  |     1|acc        |↑  |0.0000|±  |0.0000|
[run_spanish_evaluation] [37m[lm_eval] |                                |       |none  |     1|acc_norm   |↑  |0.1667|±  |0.1667|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |                                |       |none  |     1|acc_norm   |↑  |0.1667|±  |0.1667|
[run_spanish_evaluation] [37m[lm_eval] |   - teleia_pce                 |      1|none  |     1|acc        |↑  |0.2857|±  |0.1844|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |   - teleia_pce                 |      1|none  |     1|acc        |↑  |0.2857|±  |0.1844|
[run_spanish_evaluation] [37m[lm_eval] |                                |       |none  |     1|acc_norm   |↑  |0.2857|±  |0.1844|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |                                |       |none  |     1|acc_norm   |↑  |0.2857|±  |0.1844|
[run_spanish_evaluation] [37m[lm_eval] |   - teleia_siele               |      1|none  |     1|acc        |↑  |0.8750|±  |0.1250|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |   - teleia_siele               |      1|none  |     1|acc        |↑  |0.8750|±  |0.1250|
[run_spanish_evaluation] [37m[lm_eval] |                                |       |none  |     1|acc_norm   |↑  |0.7500|±  |0.1637|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |                                |       |none  |     1|acc_norm   |↑  |0.7500|±  |0.1637|
[run_spanish_evaluation] [37m[lm_eval] |  - wnli_es                     |      1|none  |     1|acc        |↑  |0.8000|±  |0.1333|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  - wnli_es                     |      1|none  |     1|acc        |↑  |0.8000|±  |0.1333|
[run_spanish_evaluation] [37m[lm_eval] |  - xnli_es_spanish_bench       |      1|none  |     1|acc        |↑  |0.4000|±  |0.1633|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  - xnli_es_spanish_bench       |      1|none  |     1|acc        |↑  |0.4000|±  |0.1633|
[run_spanish_evaluation] [37m[lm_eval] |  Groups  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  Groups  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
[run_spanish_evaluation] [37m[lm_eval] |----------|------:|------|------|--------|---|-----:|---|-----:|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |----------|------:|------|------|--------|---|-----:|---|-----:|
[run_spanish_evaluation] [37m[lm_eval] |latam_es  |      1|none  |      |acc     |↑  |0.4512|±  |0.0511|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |latam_es  |      1|none  |      |acc     |↑  |0.4512|±  |0.0511|
[run_spanish_evaluation] [37m[lm_eval] | - spanish|      1|none  |      |acc     |↑  |0.4691|±  |0.0511|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] | - spanish|      1|none  |      |acc     |↑  |0.4691|±  |0.0511|
[run_spanish_evaluation] [37m[lm_eval] |  - teleia|      1|none  |      |acc     |↑  |0.4286|±  |0.0781|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |  - teleia|      1|none  |      |acc     |↑  |0.4286|±  |0.0781|
[run_spanish_evaluation] [37m[lm_eval] |          |       |none  |      |acc_norm|↑  |0.4286|±  |0.0998|[0m
[run_spanish_evaluation] 2025-09-17 03:27:06 | INFO     | benchy.lm_eval       | [lm_eval] |          |       |none  |      |acc_norm|↑  |0.4286|±  |0.0998|
[run_spanish_evaluation] [37mlm_eval completed successfully[0m
[run_spanish_evaluation] 2025-09-17 03:27:08 | INFO     | benchy.lm_eval       | === LM Evaluation COMPLETED SUCCESSFULLY ===
[run_spanish_evaluation] 2025-09-17 03:27:08 | INFO     | benchy.lm_eval       | Output saved to: /home/mauro/dev/lm-evaluation-harness/output/spanish
[37mStep [0m[38;5;105mrun_spanish_evaluation[37m has finished in [0m[38;5;105m1m22s[37m.[0m
[37mStep [0m[38;5;105mupload_results[37m has started.[0m
[upload_results] [37mStarting upload for model: google/gemma-3n-E4B-it[0m
[upload_results] 2025-09-17 03:27:09 | INFO     | benchy.upload        | === Starting Upload ===
[upload_results] 2025-09-17 03:27:09 | INFO     | benchy.upload        | Model: google/gemma-3n-E4B-it
[upload_results] 2025-09-17 03:27:09 | INFO     | benchy.upload        | Script path: /home/mauro/dev/leaderboard
[upload_results] 2025-09-17 03:27:09 | INFO     | benchy.upload        | Script name: run_pipeline.py
[upload_results] [37mExecuting command: uv run run_pipeline.py[0m
[upload_results] 2025-09-17 03:27:09 | INFO     | benchy.upload        | Upload command: uv run run_pipeline.py
[upload_results] [37m[upload] warning: [0m[38;5;105mVIRTUAL_ENV=/home/mauro/dev/benchy/.venv[37m does not match the project environment path [0m[38;5;105m.venv[37m and will be ignored; use [0m[38;5;105m--active[37m to target the active environment instead[0m
[upload_results] 2025-09-17 03:27:09 | INFO     | benchy.upload        | [upload] warning: `VIRTUAL_ENV=/home/mauro/dev/benchy/.venv` does not match the project environment path `.venv` and will be ignored; use `--active` to target the active environment instead
[upload_results] [37m[upload] 🚀 Starting leaderboard pipeline...[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] 🚀 Starting leaderboard pipeline...
[upload_results] [37m[upload] 🔄 Converting lm-evaluation-harness results to leaderboard format[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] 🔄 Converting lm-evaluation-harness results to leaderboard format
[upload_results] [37m[upload] Running: /home/mauro/dev/leaderboard/.venv/bin/python3 convert_lm_eval_to_leaderboard.py --lm-eval-dir /home/mauro/dev/lm-evaluation-harness/output --output-dir /home/mauro/dev/leaderboard/publish[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Running: /home/mauro/dev/leaderboard/.venv/bin/python3 convert_lm_eval_to_leaderboard.py --lm-eval-dir /home/mauro/dev/lm-evaluation-harness/output --output-dir /home/mauro/dev/leaderboard/publish
[upload_results] [37m[upload] ✅ Success![0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] ✅ Success!
[upload_results] [37m[upload] Found 10 result files to convert[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Found 10 result files to convert
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/portuguese/google__gemma-3n-E4B-it/results_2025-09-17T03-25-40.746931.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/portuguese/google__gemma-3n-E4B-it/results_2025-09-17T03-25-40.746931.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.115839.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.115839.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.116388.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.116388.json
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/portuguese/google__gemma-3n-E4B-it/results_2025-09-17T03-21-52.285354.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/portuguese/google__gemma-3n-E4B-it/results_2025-09-17T03-21-52.285354.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.116605.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.116605.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.117062.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.117062.json
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/google__gemma-3n-E4B-it/results_2025-09-15T22-25-12.792054.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/google__gemma-3n-E4B-it/results_2025-09-15T22-25-12.792054.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.118511.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.118511.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/google_gemma-3n-E4B-it_eval_request_2025-09-17T03-27-10.124561.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/google_gemma-3n-E4B-it_eval_request_2025-09-17T03-27-10.124561.json
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T03-23-16.464742.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T03-23-16.464742.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.124992.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.124992.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.126320.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.126320.json
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T03-05-09.647274.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T03-05-09.647274.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.126705.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.126705.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.127995.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.127995.json
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T03-27-04.936261.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T03-27-04.936261.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.128372.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.128372.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.129671.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.129671.json
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T02-43-45.996038.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T02-43-45.996038.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.130050.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.130050.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.131347.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.131347.json
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T02-20-25.256310.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T02-20-25.256310.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.131729.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.131729.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.133009.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.133009.json
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T02-58-43.481451.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T02-58-43.481451.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.133378.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.133378.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.134681.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.134681.json
[upload_results] [37m[upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T03-11-41.171671.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Processing: /home/mauro/dev/lm-evaluation-harness/output/spanish/google__gemma-3n-E4B-it/results_2025-09-17T03-11-41.171671.json
[upload_results] [37m[upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.135052.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created result file: /home/mauro/dev/leaderboard/publish/results/google/gemma-3n-E4B-it/results_2025-09-17T03-27-10.135052.json
[upload_results] [37m[upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.136355.json[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Created request file: /home/mauro/dev/leaderboard/publish/requests/_eval_request_2025-09-17T03-27-10.136355.json
[upload_results] [37m[upload] Conversion complete! Converted 10 files.[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Conversion complete! Converted 10 files.
[upload_results] [37m[upload] Leaderboard data available in: /home/mauro/dev/leaderboard/publish[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Leaderboard data available in: /home/mauro/dev/leaderboard/publish
[upload_results] [37m[upload] 🔄 Publishing to Hugging Face datasets[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] 🔄 Publishing to Hugging Face datasets
[upload_results] [37m[upload] Running: /home/mauro/dev/leaderboard/.venv/bin/python3 publish_to_dataset.py --publish-dir /home/mauro/dev/leaderboard/publish --results-dataset mauroibz/leaderboard-results --requests-dataset mauroibz/leaderboard-requests[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Running: /home/mauro/dev/leaderboard/.venv/bin/python3 publish_to_dataset.py --publish-dir /home/mauro/dev/leaderboard/publish --results-dataset mauroibz/leaderboard-results --requests-dataset mauroibz/leaderboard-requests
[upload_results] [37m[upload] ✅ Success![0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] ✅ Success!
[upload_results] [37m[upload] Found 38 result files and 38 request files[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Found 38 result files and 38 request files
[upload_results] [37m[upload] Uploading results...[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Uploading results...
[upload_results] [37m[upload] Dataset mauroibz/leaderboard-results already exists[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Dataset mauroibz/leaderboard-results already exists
[upload_results] [37m[upload] Uploading results to mauroibz/leaderboard-results...[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Uploading results to mauroibz/leaderboard-results...
[upload_results] [37m[upload] Successfully uploaded results to mauroibz/leaderboard-results[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Successfully uploaded results to mauroibz/leaderboard-results
[upload_results] [37m[upload] Uploading requests...[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Uploading requests...
[upload_results] [37m[upload] Dataset mauroibz/leaderboard-requests already exists[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Dataset mauroibz/leaderboard-requests already exists
[upload_results] [37m[upload] Uploading requests to mauroibz/leaderboard-requests...[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Uploading requests to mauroibz/leaderboard-requests...
[upload_results] [37m[upload] Successfully uploaded requests to mauroibz/leaderboard-requests[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Successfully uploaded requests to mauroibz/leaderboard-requests
[upload_results] [37m[upload] ✅ Successfully published all data to Hugging Face datasets![0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] ✅ Successfully published all data to Hugging Face datasets!
[upload_results] [37m[upload] Results: [0m[34mhttps://huggingface.co/datasets/mauroibz/leaderboard-results[37m[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Results: https://huggingface.co/datasets/mauroibz/leaderboard-results
[upload_results] [37m[upload] Requests: [0m[34mhttps://huggingface.co/datasets/mauroibz/leaderboard-requests[37m[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] Requests: https://huggingface.co/datasets/mauroibz/leaderboard-requests
[upload_results] [37m[upload] 🎉 Pipeline completed successfully![0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] 🎉 Pipeline completed successfully!
[upload_results] [37m[upload] 📊 Your leaderboard data is now available at:[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] 📊 Your leaderboard data is now available at:
[upload_results] [37m[upload]   Results: [0m[34mhttps://huggingface.co/datasets/mauroibz/leaderboard-results[37m[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload]   Results: https://huggingface.co/datasets/mauroibz/leaderboard-results
[upload_results] [37m[upload]   Requests: [0m[34mhttps://huggingface.co/datasets/mauroibz/leaderboard-requests[37m[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload]   Requests: https://huggingface.co/datasets/mauroibz/leaderboard-requests
[upload_results] [37m[upload] 📝 Update your envs.py file with these dataset names:[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload] 📝 Update your envs.py file with these dataset names:
[upload_results] [37m[upload]   RESULTS_REPO = "mauroibz/leaderboard-results"[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload]   RESULTS_REPO = "mauroibz/leaderboard-results"
[upload_results] [37m[upload]   QUEUE_REPO = "mauroibz/leaderboard-requests"[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | [upload]   QUEUE_REPO = "mauroibz/leaderboard-requests"
[upload_results] [37mUpload completed successfully[0m
[upload_results] 2025-09-17 03:27:15 | INFO     | benchy.upload        | === Upload COMPLETED SUCCESSFULLY ===
[37mStep [0m[38;5;105mupload_results[37m has finished in [0m[38;5;105m6.150s[37m.[0m
[37mStep [0m[38;5;105mstop_vllm_server[37m has started.[0m
[stop_vllm_server] [37mStopping vLLM server (PID: 296140)[0m
[stop_vllm_server] 2025-09-17 03:27:16 | INFO     | benchy.vllm_server   | === Stopping vLLM Server (PID: 296140) ===
[1;36m(APIServer pid=296140)[0;0m INFO 09-17 03:27:17 [launcher.py:101] Shutting down FastAPI HTTP server.
[rank0]:[W917 03:27:17.064739160 ProcessGroupNCCL.cpp:1479] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[1;36m(APIServer pid=296140)[0;0m INFO:     Shutting down
[1;36m(APIServer pid=296140)[0;0m INFO:     Waiting for application shutdown.
[1;36m(APIServer pid=296140)[0;0m INFO:     Application shutdown complete.
[stop_vllm_server] [37m✅ vLLM server terminated gracefully[0m
[stop_vllm_server] 2025-09-17 03:27:20 | INFO     | benchy.vllm_server   | vLLM server terminated gracefully
[37mStep [0m[38;5;105mstop_vllm_server[37m has finished in [0m[38;5;105m4.105s[37m.[0m
[37mPipeline run has finished in [0m[38;5;105m3m23s[37m.[0m
[37mBenchmark pipeline completed successfully![0m
[37mResults: body=PipelineRunResponseBody(created=datetime.datetime(2025, 9, 17, 3, 23, 57, 716840), updated=datetime.datetime(2025, 9, 17, 3, 27, 20, 370364), user_id=UUID('4243a599-8ed2-4b85-825e-bf5dbedfd16e'), project_id=UUID('8cbad16e-0e18-4231-a596-c68c789661c9'), status=<ExecutionStatus.COMPLETED: 'completed'>, stack=StackResponse(body=StackResponseBody(created=datetime.datetime(2025, 9, 11, 21, 18, 7, 944580), updated=datetime.datetime(2025, 9, 11, 21, 18, 7, 944639), user_id=None), metadata=None, resources=None, id=UUID('fda986ea-0de7-462d-ad67-92fc00293536'), permission_denied=False, name='default'), pipeline=PipelineResponse(body=PipelineResponseBody(created=datetime.datetime(2025, 9, 17, 1, 34, 6, 624334), updated=datetime.datetime(2025, 9, 17, 1, 34, 6, 624370), user_id=UUID('4243a599-8ed2-4b85-825e-bf5dbedfd16e'), project_id=UUID('8cbad16e-0e18-4231-a596-c68c789661c9')), metadata=None, resources=None, id=UUID('d37b96a5-1d7f-453b-848a-fdf8318cda54'), permission_denied=False, name='benchmark_pipeline'), build=None, schedule=None, code_reference=None, deployment_id=UUID('e8c8eaf0-6515-4aa8-a955-34a134fbf9e0'), trigger_execution=None, model_version_id=None) metadata=PipelineRunResponseMetadata(run_metadata={}, config=PipelineConfiguration(enable_cache=None, enable_artifact_metadata=None, enable_artifact_visualization=None, enable_step_logs=None, enable_pipeline_logs=None, settings={}, tags=None, extra={}, failure_hook_source=None, success_hook_source=None, model=None, parameters=None, retry=None, substitutions={'date': '2025_09_17', 'time': '03_23_57_699369'}, name='benchmark_pipeline'), start_time=datetime.datetime(2025, 9, 17, 3, 23, 57, 699369), end_time=datetime.datetime(2025, 9, 17, 3, 27, 20, 370318), client_environment={'environment': 'native', 'os': 'linux', 'linux_distro': 'ubuntu', 'linux_distro_like': 'debian', 'linux_distro_version': '24.04', 'python_version': '3.12.3'}, orchestrator_environment={'environment': 'native', 'os': 'linux', 'linux_distro': 'ubuntu', 'linux_distro_like': 'debian', 'linux_distro_version': '24.04', 'python_version': '3.12.3'}, orchestrator_run_id='b47ce7cc-40fd-4002-a99b-fabab28a9a01', code_path=None, template_id=None, is_templatable=False) resources=PipelineRunResponseResources(user=UserResponse(body=UserResponseBody(created=datetime.datetime(2025, 9, 11, 21, 18, 8, 302535), updated=datetime.datetime(2025, 9, 11, 21, 18, 37, 956224), active=True, activation_token=None, full_name='Mauro', email_opted_in=False, is_service_account=False, is_admin=True, default_project_id=None, avatar_url=None), metadata=None, resources=None, id=UUID('4243a599-8ed2-4b85-825e-bf5dbedfd16e'), permission_denied=False, name='default'), model_version=None, tags=[], logs=LogsResponse(body=LogsResponseBody(created=datetime.datetime(2025, 9, 17, 3, 23, 57, 726710), updated=datetime.datetime(2025, 9, 17, 3, 23, 57, 726747), uri='/home/mauro/.config/zenml/local_stores/32cc2844-d68a-4e96-8190-0131de826f57/pipeline_runs/logs/a110a1ac-c32a-42bc-8ece-6b5827e2cf36.log', source='client'), metadata=None, resources=None, id=UUID('dd5fc3e8-8f27-482a-96c8-ae82b61d383d'), permission_denied=False), log_collection=[LogsResponse(body=LogsResponseBody(created=datetime.datetime(2025, 9, 17, 3, 23, 57, 726710), updated=datetime.datetime(2025, 9, 17, 3, 23, 57, 726747), uri='/home/mauro/.config/zenml/local_stores/32cc2844-d68a-4e96-8190-0131de826f57/pipeline_runs/logs/a110a1ac-c32a-42bc-8ece-6b5827e2cf36.log', source='client'), metadata=None, resources=None, id=UUID('dd5fc3e8-8f27-482a-96c8-ae82b61d383d'), permission_denied=False)]) id=UUID('7493e2f4-45db-4eaf-8db4-8862834b5b29') permission_denied=False name='TEST_gemma_3n_E4B_it_2025_09_17_03_23_56'[0m
2025-09-17 03:27:21 | INFO     | benchy.summary       | === RUN SUMMARY ===
2025-09-17 03:27:21 | INFO     | benchy.summary       | Model: google/gemma-3n-E4B-it
2025-09-17 03:27:21 | INFO     | benchy.summary       | Return code: 0
2025-09-17 03:27:21 | INFO     | benchy.summary       | Log file: logs/benchy_google_gemma-3n-E4B-it_20250917_032356.log
2025-09-17 03:27:21 | INFO     | benchy.summary       | Run completed successfully
2025-09-17 03:27:21 | INFO     | benchy.summary       | === END SUMMARY ===
